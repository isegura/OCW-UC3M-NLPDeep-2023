{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\"/>\n",
        "\n",
        "<img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>    "
      ],
      "metadata": {
        "id": "mA66S9V1H8T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings\n",
        "\n",
        "En este cuaderno, aprenderemos a cargar un modelo de word embeddings utilizando la librería gensim. También trabajaremos con el modelo para descubrir que funcionalidades nos permite hacer: "
      ],
      "metadata": {
        "id": "Op-cuN5XFqdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero de todo, vamos a instalar [gensim](#https://radimrehurek.com/gensim/), una librería de Python que nos permite tanto entrenar modelos de word embeddings como cargar modelos pre-entrenados y utlizarlos para obtener los vectores de palabras. "
      ],
      "metadata": {
        "id": "_NbMGnCqH2nY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neA-Mq4gJyIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ca32ee-3929-4047-dd83-ebd5f623daac"
      },
      "source": [
        "!pip install --upgrade gensim\n",
        "#!pip gensim --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (4.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: FuzzyTM>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (1.3.5)\n",
            "Requirement already satisfied: pyfume in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
            "Requirement already satisfied: fst-pso in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
            "Requirement already satisfied: simpful in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.15.0)\n",
            "Requirement already satisfied: miniful in /usr/local/lib/python3.8/dist-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku6NHQvcP1Ed"
      },
      "source": [
        "## Loading a pre-trained word embedding model by using gensim\n",
        "\n",
        "El API de gensim nos permite cargar directamente modelos pre-entrenados. Por ejemplos, en la siguiente celda vamos a cargar el modelo \n",
        "\n",
        "Pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased.\n",
        "\n",
        "\n",
        "'glove-twitter-25', un modelo pre-entrenado utilizando 2billones de tweets con 27B de tokens, y que como resultado se ha obtenido un diccionario de 1.2 millones de palabras (uncased). \n",
        "\n",
        "La operación puede tardar unos minutos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpTYY4SrP4O8"
      },
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "También es posible cargar un modelo desde local. Por ejemplo, vamos a salvar el modelo anterior, y lo vamos a cargar en una nueva variable new_model:"
      ],
      "metadata": {
        "id": "aQw2G9vWGqTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.save('model.bin')\n",
        "new_model = KeyedVectors.load('model.bin')"
      ],
      "metadata": {
        "id": "Lt9BZpB7GtyL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consultemos el vector asociado a una palabra concreta, 'mother'. Podemos ver que es un vector de dimensión 100. "
      ],
      "metadata": {
        "id": "hBxhpjI4Py9J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVr-IPpnQHvo",
        "outputId": "c5ae08e7-9aa6-45c6-8a70-7ea524f7e274"
      },
      "source": [
        "vector = model['mother']  # numpy vector of a word\n",
        "print(vector.shape)\n",
        "print(vector)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "[ 0.60587   0.027989  0.018495 -0.018674 -0.39562   1.0309   -0.35793\n",
            "  0.20527   0.3293    0.035267 -0.38475   0.31452   0.32538   0.70024\n",
            "  0.13935  -0.58923   0.36985  -0.080566 -0.59721   1.0215   -0.55154\n",
            "  0.042073  0.34687   0.86511   0.63521   0.52616  -0.92199  -1.4634\n",
            "  0.34517   0.58921   0.12295   0.7323    1.0468    0.065458 -0.27033\n",
            " -0.095179  0.20613   0.22589   0.90409  -0.11252  -0.58059   0.036599\n",
            "  0.32003  -0.53638   0.19297   0.035694 -0.56487   0.1527    0.70196\n",
            " -0.24191   0.10476  -0.23424   1.212     1.1612   -0.033677 -1.9996\n",
            " -0.79448  -0.087088  0.51475   0.44601   0.638     0.89893   0.17408\n",
            " -0.32006   0.41652   0.23289   0.50642   0.26938  -0.1453    0.1207\n",
            " -0.26246   0.16991   0.16702  -0.042041  0.64841   0.9827   -0.092602\n",
            " -0.56797  -0.63854  -0.38415  -0.13816   0.43137   0.44748   0.24486\n",
            " -1.5669   -0.80245  -0.15123  -0.18795  -0.4888   -0.67834   0.27133\n",
            " -0.36768   1.1268    0.44722  -0.91335  -0.055973 -0.38328  -0.62756\n",
            " -0.24055  -0.22544 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo de word embeddings nos permite calcular la similitud entre dos palabras. Si el resultado es cercano a 1, significa que ambas palabras tienen un significado similar. "
      ],
      "metadata": {
        "id": "G6d-YCXzHLzi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzL0-OLlPNQP",
        "outputId": "f2ecccc4-a6a1-45da-cfd1-c332f1203310"
      },
      "source": [
        "similarity = model.similarity('mother', 'teeth')\n",
        "print(similarity)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2704376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn7IPJQkPcE9",
        "outputId": "36f22aea-36f5-41fb-a99b-48a2e3a3b74d"
      },
      "source": [
        "similarity = model.similarity('brush', 'brushes')\n",
        "print(similarity)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.595461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como era de esperar 'brush' y 'brushes' tienen un grado de similitud mayor que el que hay entre 'mother' y 'teeth'.\n",
        "\n",
        "Veamos ahora la similitud entre 'man' y otras palabras como 'woman', 'guy' o 'boy'."
      ],
      "metadata": {
        "id": "NeNSZwPFQFrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word1='man',\n",
        "for word2 in ['woman', 'guy', 'boy']:\n",
        "    similarity = model.similarity(word1, word2)\n",
        "    print(\"similarity of {} and {} = {}\".format(word1,word2,similarity))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDLv51_vHacn",
        "outputId": "7dbea719-d5da-4845-efdd-45088ad648a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity of ('man',) and woman = [0.8323495]\n",
            "similarity of ('man',) and guy = [0.6679584]\n",
            "similarity of ('man',) and boy = [0.79148716]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como era de esperar 'boy', seguida por 'guy' guardan una mayor similitud con 'man' que 'woman'."
      ],
      "metadata": {
        "id": "dIpHLrJBQkKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método *most_similar* nos permite obtener una lista de palabras similares a una dada, ordenadas de mayor a menor similitud. "
      ],
      "metadata": {
        "id": "X9txV2y9ID9g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvIIWPnMVTU7",
        "outputId": "c7852550-1384-4df5-e5f6-16cde7aeea0d"
      },
      "source": [
        "model.most_similar('truck')\n",
        "#model.most_similar('aspirin')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('car', 0.8597878217697144),\n",
              " ('trucks', 0.8078932166099548),\n",
              " ('vehicle', 0.7879196405410767),\n",
              " ('bus', 0.7633007764816284),\n",
              " ('pickup', 0.7436763644218445),\n",
              " ('tractor', 0.7433986067771912),\n",
              " ('cars', 0.741030752658844),\n",
              " ('driver', 0.7295383214950562),\n",
              " ('parked', 0.7291535139083862),\n",
              " ('lorry', 0.7239130139350891)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver como 'good' es la segunda palabra propuesta como más similar a 'bad'. Esto no es cierto, pero el método la propone porque bad y good suelen ocurrir en contextos muy parecidos. "
      ],
      "metadata": {
        "id": "bIVSrMBEWi0w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmWTD3jxVgH7",
        "outputId": "d38f70b1-fb5b-4220-c39e-d50fa6985b06"
      },
      "source": [
        "model.most_similar('bad')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('worse', 0.7929712533950806),\n",
              " ('good', 0.7702797651290894),\n",
              " ('things', 0.7653602957725525),\n",
              " ('too', 0.7630148530006409),\n",
              " ('thing', 0.7609668374061584),\n",
              " ('lot', 0.7443646788597107),\n",
              " ('kind', 0.7408681511878967),\n",
              " ('because', 0.7398799061775208),\n",
              " ('really', 0.7376540899276733),\n",
              " (\"n't\", 0.7336540818214417)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input for the method *most_similar* could be words or vectors. "
      ],
      "metadata": {
        "id": "5_nh5l5FI1va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector=model['bad']  # numpy vector of a word\n",
        "print(model.most_similar('bad'))\n",
        "print(model.most_similar([vector]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJWvQC6OIpdu",
        "outputId": "e0ada3f1-0525-4feb-aed8-7a242288bf5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('worse', 0.7929712533950806), ('good', 0.7702797651290894), ('things', 0.7653602957725525), ('too', 0.7630148530006409), ('thing', 0.7609668374061584), ('lot', 0.7443646788597107), ('kind', 0.7408681511878967), ('because', 0.7398799061775208), ('really', 0.7376540899276733), (\"n't\", 0.7336540818214417)]\n",
            "[('bad', 1.0), ('worse', 0.7929712533950806), ('good', 0.7702798247337341), ('things', 0.7653602957725525), ('too', 0.7630148530006409), ('thing', 0.7609667778015137), ('lot', 0.7443647980690002), ('kind', 0.7408681511878967), ('because', 0.7398799061775208), ('really', 0.7376540899276733)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método *similar_by_word* es muy similar al método anterior, *most_similar*. La principal diferencia es que mientras most_similar puede recibir como entrada una palabra o un vector, *similar_by_word* must be always a word, únicamente acepta palabras:"
      ],
      "metadata": {
        "id": "KuZMqT8lJFsR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVoiUSGAQaHz",
        "outputId": "9efa56aa-be19-4ac7-a214-01e2e2e02fef"
      },
      "source": [
        "result = model.similar_by_word(\"truck\") #cat\n",
        "for r in result:\n",
        "    print(r)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('car', 0.8597878217697144)\n",
            "('trucks', 0.8078932166099548)\n",
            "('vehicle', 0.7879196405410767)\n",
            "('bus', 0.7633007764816284)\n",
            "('pickup', 0.7436763644218445)\n",
            "('tractor', 0.7433986067771912)\n",
            "('cars', 0.741030752658844)\n",
            "('driver', 0.7295383214950562)\n",
            "('parked', 0.7291535139083862)\n",
            "('lorry', 0.7239130139350891)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método *distance* proporciona la distancia del cosenoentre dos palabras. El método *similarity* proporciona el grado de similitud, que es, 1 menos la distancia del coseno entre las dos palabras:\n",
        "\n",
        "$similarity = 1 - distance = 1 - cosine$"
      ],
      "metadata": {
        "id": "aC2fVQwoJWhr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwZmM9z0Qu50",
        "outputId": "09a11591-34f2-4b63-ac5c-888b18cfbc5a"
      },
      "source": [
        "w1=\"woman\"\n",
        "\n",
        "distance = model.distance(w1, w1)\n",
        "print(f\"{distance:.1f}\")\n",
        "\n",
        "\n",
        "similarity = model.similarity(w1, w1)\n",
        "print(f\"{similarity:.1f}\")\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzLpuG95SFms",
        "outputId": "c145df7a-826a-4abe-8263-e9b10206346c"
      },
      "source": [
        "distance = model.distance(\"woman\", \"man\")\n",
        "similarity = model.similarity('woman', 'man')\n",
        "print(f\"{distance:.1f}\",f\"{similarity:.1f}\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk3YRaLUSIse",
        "outputId": "b915fb97-f6a8-464c-9659-05dfe2820a0d"
      },
      "source": [
        "w1= 'woman'\n",
        "for w2 in ['cosine', 'girl', 'wife']:\n",
        "    distance = model.distance(w1,w2)\n",
        "    similarity = model.similarity(w1,w2)\n",
        "    print(w1, w2, '-> distancia:', f\"{distance:.1f}\", 'similitud:', f\"{similarity:.1f}\")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman cosine -> distancia: 1.2 similitud: -0.2\n",
            "woman girl -> distancia: 0.2 similitud: 0.8\n",
            "woman wife -> distancia: 0.2 similitud: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yiZF8LmSemt",
        "outputId": "d8b83b0f-199f-4bde-b0a4-b57d32f355cd"
      },
      "source": [
        "w1= 'man'\n",
        "for w2 in ['cosine', 'boy', 'husband']:\n",
        "    distance = model.distance(w1,w2)\n",
        "    similarity = model.similarity(w1,w2)\n",
        "    print(w1, w2, '-> distancia:', f\"{distance:.1f}\", 'similitud:', f\"{similarity:.1f}\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man cosine -> distancia: 1.1 similitud: -0.1\n",
            "man boy -> distancia: 0.2 similitud: 0.8\n",
            "man husband -> distancia: 0.3 similitud: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKwsqynqyPhI"
      },
      "source": [
        "El método 'does_match' es capaz de identificar en un conjunto de palabras la palabra que no encaja:\n",
        "Which word from the given list doesn’t go with the others?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRmZQRKtUGCH",
        "outputId": "b9dc7e05-697b-47ce-c395-71e38ef6461f"
      },
      "source": [
        "print(model.doesnt_match(['breakfast', 'house', 'dinner', 'lunch']))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "house\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WYb_ZgeUHuw",
        "outputId": "1e1ef00b-1888-4e0b-9229-0a79d8939d65"
      },
      "source": [
        "print(model.doesnt_match(\"car ship woman train\".split()))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYQja5X0yIJW"
      },
      "source": [
        "##  n_similarity\n",
        "Compute cosine similarity between two sets of words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-JJV7QJT3TO",
        "outputId": "eada0dec-166f-4d11-f163-5c955493eebd"
      },
      "source": [
        "similarity = model.n_similarity(['one', 'heart'], ['japanese', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfkfHNxFT0iN",
        "outputId": "bc106742-c7bb-42c0-d57a-65e48ffe1d95"
      },
      "source": [
        "similarity = model.n_similarity(['sushi', 'bar'], ['japanese', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPeWROHTT89U",
        "outputId": "87ed8908-d009-48ba-a81b-99dd6d071189"
      },
      "source": [
        "similarity = model.n_similarity(['sushi', 'red'], ['blue', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfmCph3pU2sh"
      },
      "source": [
        "El siguiente método, most_similar_cosmul, nos permite obtener una lista de palabras similar a un conjunto dado, pero con significado opuesto a otro conjunto de palabras: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDWvm-4aQDv3",
        "outputId": "c191407d-d089-4d15-c0ca-d7317db6c86c"
      },
      "source": [
        "# Use a different similarity measure: \"cosmul\".\n",
        "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])\n",
        "\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen: 0.8965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1NO4DZXUfNC",
        "outputId": "551abb3a-ec0d-421b-af31-b6742d21332d"
      },
      "source": [
        "result = model.most_similar_cosmul(positive=['madrid', 'france'], negative=['spain'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paris: 0.9525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yZF7P1UUuVH",
        "outputId": "47ba5a56-eff5-4f27-f596-c4c0d73a1726"
      },
      "source": [
        "result = model.most_similar_cosmul(positive=['baghdad', 'england'], negative=['london'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iraq: 0.8781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pautUMgxVpRI",
        "outputId": "aec53dc7-b041-4035-9039-30f085445a0a"
      },
      "source": [
        "result = model.most_similar_cosmul(positive=['spain', 'barcelona'], negative=['madrid'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "portugal: 0.9031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td0nKnS6P95m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9796334d-b41f-4995-e3fc-eebe7cc5cadf"
      },
      "source": [
        "# Check the \"most similar words\", using the default \"cosine similarity\" measure.\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSpbZmKnLDL6"
      },
      "source": [
        "También es posible obtener la similitud entre dos oraciones (o documentos)\n",
        "\n",
        "\n",
        "\n",
        "https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install POT==0.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otOO1iw2XsBm",
        "outputId": "23e413e4-9cc2-4524-f6bb-6f4a1bf6b131"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting POT==0.4.0\n",
            "  Downloading POT-0.4.0.tar.gz (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from POT==0.4.0) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from POT==0.4.0) (1.7.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from POT==0.4.0) (0.29.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from POT==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->POT==0.4.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->POT==0.4.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->POT==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->POT==0.4.0) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->POT==0.4.0) (1.15.0)\n",
            "Building wheels for collected packages: POT\n",
            "  Building wheel for POT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for POT: filename=POT-0.4.0-cp38-cp38-linux_x86_64.whl size=296780 sha256=e3891321f8f4ae91fb31d3c32c8f89d65fe129826df34aa430a3ea80608be411\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/a2/14/41d41262c65ab560964e367fc6e0203dc1a6657d2e22d0d5e7\n",
            "Successfully built POT\n",
            "Installing collected packages: POT\n",
            "Successfully installed POT-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olvlq1fuSvJe",
        "outputId": "4142ee4a-3f59-492a-cfa1-4c13558c357b"
      },
      "source": [
        "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
        "\n",
        "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
        "sentence_president3 = 'The president greets the media in Illinois'.lower().split()\n",
        "\n",
        "distance = model.wmdistance(sentence_obama, sentence_president)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(sentence_obama, sentence_president3)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(sentence_president, sentence_president3)\n",
        "print(f\"{distance:.4f}\")\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6182\n",
            "0.3908\n",
            "0.2274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUn9esFiTaHU",
        "outputId": "a863e54b-875b-463b-b9b6-4b4f661db448"
      },
      "source": [
        "text1 = 'The hotel was very expensive and not good'.lower().split()\n",
        "text2 = 'The hotel was very good and not expensive'.lower().split()\n",
        "text3 = 'The hotel was very bad and not cheap'.lower().split()\n",
        "\n",
        "text4 = 'The best result was achieved by BERT'.lower().split()\n",
        "\n",
        "distance = model.wmdistance(text1, text2)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(text1, text3)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(text1, text4)\n",
        "print(f\"{distance:.4f}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0000\n",
            "0.1686\n",
            "0.6942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí os dejo el código de una función que os permite obtener un gráfico del modelo de word embeddings (tarda mucho tiempo):"
      ],
      "metadata": {
        "id": "mKKYJzQAX8MB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPkBgMFjYa3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd1fb1f-33ad-4e5b-926d-d11aa257cafe"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def tsne_plot(word_vectors):\n",
        "    \"Create TSNE model and plot it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    words=list(word_vectors.index_to_key)\n",
        "    for word in words:\n",
        "        tokens.append(word_vectors[word])\n",
        "        labels.append(word)\n",
        "    \n",
        "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(tokens)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "        \n",
        "    plt.figure(figsize=(18, 18)) \n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                     xy=(x[i], y[i]),\n",
        "                     xytext=(5, 2),\n",
        "                     textcoords='offset points',\n",
        "                     ha='right',\n",
        "                     va='bottom')\n",
        "    plt.show()\n",
        "   \n",
        "tsne_plot(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}
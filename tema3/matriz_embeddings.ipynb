{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4btRBQljoPw8"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\"/>\n",
        "\n",
        "<img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>    \n",
        "\n",
        "<a href=\"http://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project07B%20-%20Text%20Classification%20Deep%20Learning%20CNN%20Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f64bBXyhpxTR"
      },
      "source": [
        "# Cómo crear una matriz de word embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tQuGHo4aBe1"
      },
      "source": [
        "El tema anterior estuvo dedicado a implementar un modelo CNN para abordar la tarea de clasificación. \n",
        "En dicho modelo, los tokens eran reemplazados por vectores creados de forma random (internamente lo hace la capa Embedding). \n",
        "\n",
        "En este notebook, aprenderemos a crear una matriz de word embeddings. La matriz tendrá tantas filas como número de palabras distintas en nuestra colección de textos. Cada fila será el word embedding para una determinada palabra recuperado de un modelo pre-entrenado de word embedding. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a utilizar el dataset EXIST. Recuerda que debemos el dataset debe solicitarse a los organizadores de la competición: jcalbornoz@lsi.uned.es, frodriguez.sanchez@invi.uned.es or lplaza@lsi.uned.es\n",
        "\n",
        "The dataset should only be used for scientific or research purposes. Any other use is explicitly prohibited.\n",
        "The datasets must not be redistributed or shared in part or full to any third party. Redirect interested parties to this website.\n",
        "All data released for these tasks are under the CC BY-SA 4.0 License (https://creativecommons.org/licenses/by-sa/4.0/legalcode).\n",
        "Data must not be used for providing surveillance, analyses or research that isolates a group of individuals or any single individual for any unlawful or discriminatory purpose.\n"
      ],
      "metadata": {
        "id": "rf3u4dW1uwp8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXV_Kwa-dNPU"
      },
      "source": [
        "Vamos a cargar únicamente los textos en inglés del conjunto de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# monta disco de google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Indica la ruta de la carpeta de Google Drive\n",
        "# donde está tu dataset\n",
        "PATH = \"/content/drive/My Drive/Colab Notebooks/data/exist2022/\"\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(PATH+\"EXIST2021_training.tsv\",  sep='\\t') \n",
        "\n",
        "df_train = df_train[df_train['language']=='en']\n",
        "print('tamaño training:', df_train.shape)\n",
        "df_train.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "sqRUUlnWvNk2",
        "outputId": "b807a10c-c8b6-4f2e-b920-b86d700af71a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "tamaño training: (3436, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   test_case  id   source language  \\\n",
              "0  EXIST2021   1  twitter       en   \n",
              "1  EXIST2021   2  twitter       en   \n",
              "2  EXIST2021   3  twitter       en   \n",
              "3  EXIST2021   4  twitter       en   \n",
              "4  EXIST2021   5  twitter       en   \n",
              "\n",
              "                                                text       task1  \\\n",
              "0  She calls herself \"anti-feminazi\" how about sh...      sexist   \n",
              "1  Now, back to these women, the brave and the be...  non-sexist   \n",
              "2  @CurvyBandida @Xalynne_B Wow, your skirt is ve...      sexist   \n",
              "3  @AurelieGuiboud Incredible!  Beautiful!But I l...  non-sexist   \n",
              "4  i find it extremely hard to believe that kelly...  non-sexist   \n",
              "\n",
              "                    task2  \n",
              "0  ideological-inequality  \n",
              "1              non-sexist  \n",
              "2         objectification  \n",
              "3              non-sexist  \n",
              "4              non-sexist  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cb46a57-d900-4888-ab17-de9ab107454d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_case</th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "      <th>language</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>1</td>\n",
              "      <td>twitter</td>\n",
              "      <td>en</td>\n",
              "      <td>She calls herself \"anti-feminazi\" how about sh...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>ideological-inequality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>2</td>\n",
              "      <td>twitter</td>\n",
              "      <td>en</td>\n",
              "      <td>Now, back to these women, the brave and the be...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>3</td>\n",
              "      <td>twitter</td>\n",
              "      <td>en</td>\n",
              "      <td>@CurvyBandida @Xalynne_B Wow, your skirt is ve...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>objectification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>4</td>\n",
              "      <td>twitter</td>\n",
              "      <td>en</td>\n",
              "      <td>@AurelieGuiboud Incredible!  Beautiful!But I l...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>5</td>\n",
              "      <td>twitter</td>\n",
              "      <td>en</td>\n",
              "      <td>i find it extremely hard to believe that kelly...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cb46a57-d900-4888-ab17-de9ab107454d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cb46a57-d900-4888-ab17-de9ab107454d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cb46a57-d900-4888-ab17-de9ab107454d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length_train = df_train['text'].apply(lambda text: len(text))\n",
        "length_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRZ9xwWTv9_y",
        "outputId": "8cb4a1b3-000d-4284-d97e-84752ab59126"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3436.000000\n",
              "mean      176.182771\n",
              "std       102.405307\n",
              "min        13.000000\n",
              "25%        89.750000\n",
              "50%       171.000000\n",
              "75%       262.000000\n",
              "max       962.000000\n",
              "Name: text, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a entrenar el tokenizador de keras con los textos del conjunto de entrenamiento:"
      ],
      "metadata": {
        "id": "iPyoiZtOvljo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences \n",
        "\n",
        "tokenizer = Tokenizer(oov_token = True)\n",
        "X_train = list(df_train['text'])\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "tokenizer.word_index['<PAD>'] = 0\n",
        "\n",
        "NUM_WORDS=len(tokenizer.word_index)\n",
        "print(\"Tamaño del vocabulario ={}\".format(NUM_WORDS))\n",
        "\n",
        "MAX_LEN = 300\n",
        "print(\"Longitud secuencia máxima ={}\".format(MAX_LEN))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaP55hxAvmPo",
        "outputId": "784faa6d-2d6a-492c-a6ef-4eab64cbe649"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario =16645\n",
            "Longitud secuencia máxima =300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Únicamente hemos cargado los textos en inglés, porque vamos a cargar un modelo pre-entrenado de word embeddings para el inglés. \n",
        "\n",
        "Vamos a crear ahora la matriz de word embeddings. Para ello cargamos un modelo pre-entrenado con word embeddings para inglés. Es un modelo pequeño para que se cargue rapidamente. Puedes probar con otros modelos de word embeddings (https://github.com/RaRe-Technologies/gensim-data)."
      ],
      "metadata": {
        "id": "Z64KPCIJ4uIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez cargado el modelo, inicializamos la matriz con 0. La matriz tiene tantas filas como palabras en el vocabulario creado por el tokenizador a partir de la colección de textos. \n",
        "El número de columnas es igual al tamaño de los vectores. \n",
        "\n",
        "Vamos a recorrer cada palabra del vocabulario, que tiene asociado un entero, i, y para cada palabra vamos a recuperar su vector del modelo pre-entrenado, para asociarlo a la fila i. Si la palabra no existe el modelo, se lanzaría una excepción que nosotros capturamos y no hacemos anda. El vector de esa palabra sería todo 0's. \n"
      ],
      "metadata": {
        "id": "Cf398ow05mxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "\n",
        "model_we = api.load(\"glove-wiki-gigaword-50\")\n",
        "#model_we = api.load(\"word2vec-google-news-300\")     #EMBED_SIZE = 300\n",
        "\n",
        "EMBED_SIZE = 50\n",
        "\n",
        "# creamos una matriz para los textos del conjunto de entrenamiento\n",
        "embedding_matrix = np.zeros((NUM_WORDS, EMBED_SIZE))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    try:\n",
        "        embedding_vector = model_we[word]\n",
        "        # word embedding para la palabra con índice i\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        #if word does not exist, we do not udpate the matrix\n",
        "        pass\n",
        "\n",
        "print('matriz creada')\n",
        "\n"
      ],
      "metadata": {
        "id": "xKnnkmZEwzaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos las 10 primeras palabras del vocabulario y sus vectores"
      ],
      "metadata": {
        "id": "YKcXFrQZ1rF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    print(word, \"word embedding:\", embedding_matrix[i])\n",
        "    if i==10:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArjCfZWKySR5",
        "outputId": "e51035a3-4f4e-47e8-ece2-211211f52ea9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16645, 50)\n",
            "True word embedding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "the word embedding: [ 4.18000013e-01  2.49679998e-01 -4.12420005e-01  1.21699996e-01\n",
            "  3.45270008e-01 -4.44569997e-02 -4.96879995e-01 -1.78619996e-01\n",
            " -6.60229998e-04 -6.56599998e-01  2.78430015e-01 -1.47670001e-01\n",
            " -5.56770027e-01  1.46579996e-01 -9.50950012e-03  1.16579998e-02\n",
            "  1.02040000e-01 -1.27920002e-01 -8.44299972e-01 -1.21809997e-01\n",
            " -1.68009996e-02 -3.32789987e-01 -1.55200005e-01 -2.31309995e-01\n",
            " -1.91809997e-01 -1.88230002e+00 -7.67459989e-01  9.90509987e-02\n",
            " -4.21249986e-01 -1.95260003e-01  4.00710011e+00 -1.85939997e-01\n",
            " -5.22870004e-01 -3.16810012e-01  5.92130003e-04  7.44489999e-03\n",
            "  1.77780002e-01 -1.58969998e-01  1.20409997e-02 -5.42230010e-02\n",
            " -2.98709989e-01 -1.57490000e-01 -3.47579986e-01 -4.56370004e-02\n",
            " -4.42510009e-01  1.87849998e-01  2.78489990e-03 -1.84110001e-01\n",
            " -1.15139998e-01 -7.85809994e-01]\n",
            "to word embedding: [ 0.68046999 -0.039263    0.30186    -0.17792     0.42962     0.032246\n",
            " -0.41376001  0.13228001 -0.29846999 -0.085253    0.17117999  0.22419\n",
            " -0.10046    -0.43652999  0.33418     0.67846     0.057204   -0.34448001\n",
            " -0.42785001 -0.43274999  0.55962998  0.10032     0.18677001 -0.26853999\n",
            "  0.037334   -2.09319997  0.22171    -0.39868     0.20912001 -0.55725002\n",
            "  3.88260007  0.47466001 -0.95657998 -0.37788001  0.20869    -0.32752001\n",
            "  0.12751     0.088359    0.16350999 -0.21634001 -0.094375    0.018324\n",
            "  0.21048    -0.03088    -0.19722     0.082279   -0.09434    -0.073297\n",
            " -0.064699   -0.26043999]\n",
            "a word embedding: [ 0.21705     0.46515    -0.46757001  0.10082     1.01349998  0.74844998\n",
            " -0.53104001 -0.26256001  0.16812     0.13181999 -0.24909    -0.44185001\n",
            " -0.21739     0.51003999  0.13448    -0.43141001 -0.03123     0.20674001\n",
            " -0.78138    -0.20148    -0.097401    0.16088    -0.61835998 -0.18504\n",
            " -0.12461    -2.25259995 -0.22321001  0.5043      0.32257     0.15312999\n",
            "  3.96359992 -0.71364999 -0.67012     0.28388     0.21738     0.14432999\n",
            "  0.25926     0.23434     0.42739999 -0.44451001  0.13812999  0.36973\n",
            " -0.64288998  0.024142   -0.039315   -0.26036999  0.12017    -0.043782\n",
            "  0.41012999  0.1796    ]\n",
            "and word embedding: [ 0.26818001  0.14346001 -0.27877     0.016257    0.11384     0.69923002\n",
            " -0.51332003 -0.47367999 -0.33074999 -0.13834     0.27020001  0.30937999\n",
            " -0.45012    -0.4127     -0.09932     0.038085    0.029749    0.10076\n",
            " -0.25058001 -0.51818001  0.34558001  0.44922     0.48791    -0.080866\n",
            " -0.10121    -1.37769997 -0.10866    -0.23201001  0.012839   -0.46507999\n",
            "  3.84629989  0.31362     0.13643    -0.52244002  0.33019999  0.33706999\n",
            " -0.35600999  0.32431     0.12041     0.35120001 -0.069043    0.36884999\n",
            "  0.25167999 -0.24517     0.25380999  0.1367     -0.31178001 -0.63209999\n",
            " -0.25027999 -0.38097   ]\n",
            "you word embedding: [-1.09190005e-03  3.33240002e-01  3.57430011e-01 -5.40409982e-01\n",
            "  8.20320010e-01 -4.93910015e-01 -3.25879991e-01  1.99720007e-03\n",
            " -2.38289997e-01  3.55540007e-01 -6.06549978e-01  9.89319980e-01\n",
            " -2.17859998e-01  1.12360001e-01  1.14940000e+00  7.32840002e-01\n",
            "  5.11820018e-01  2.92869985e-01  2.83879995e-01 -1.35899997e+00\n",
            " -3.79509985e-01  5.09429991e-01  7.07099974e-01  6.29410028e-01\n",
            "  1.05340004e+00 -2.17560005e+00 -1.32040000e+00  4.00009990e-01\n",
            "  1.57410002e+00 -1.65999997e+00  3.77209997e+00  8.69490027e-01\n",
            " -8.04390013e-01  1.83899999e-01 -3.43320012e-01  1.07140001e-02\n",
            "  2.39690006e-01  6.67480007e-02  7.01170027e-01 -7.37020016e-01\n",
            "  2.08770007e-01  1.15640000e-01 -1.51899993e-01  8.59080017e-01\n",
            "  2.26199999e-01  1.65189996e-01  3.63090008e-01 -4.56970006e-01\n",
            " -4.89690006e-02  1.13160002e+00]\n",
            "i word embedding: [ 1.18910000e-01  1.52549997e-01 -8.20730031e-02 -7.41439998e-01\n",
            "  7.59169996e-01 -4.83280003e-01 -3.10090005e-01  5.14760017e-01\n",
            " -9.87079978e-01  6.17570011e-04 -1.50429994e-01  8.37700009e-01\n",
            " -1.07969999e+00 -5.14599979e-01  1.31879997e+00  6.20069981e-01\n",
            "  1.37789994e-01  4.71080005e-01 -7.28740022e-02 -7.26750016e-01\n",
            " -7.41159976e-01  7.52629995e-01  8.81799996e-01  2.95610011e-01\n",
            "  1.35479999e+00 -2.57010007e+00 -1.35230005e+00  4.58799988e-01\n",
            "  1.00680006e+00 -1.18560004e+00  3.47370005e+00  7.78980017e-01\n",
            " -7.29290009e-01  2.51020014e-01 -2.61559993e-01 -3.46839994e-01\n",
            "  5.58409989e-01  7.50980020e-01  4.98299986e-01 -2.68229991e-01\n",
            " -2.74430006e-03 -1.82980001e-02 -2.80959994e-01  5.53179979e-01\n",
            "  3.77059989e-02  1.85550004e-01 -1.50250003e-01 -5.75119972e-01\n",
            " -2.66710013e-01  9.21209991e-01]\n",
            "of word embedding: [ 0.70853001  0.57088    -0.4716      0.18048     0.54448998  0.72602999\n",
            "  0.18156999 -0.52393001  0.10381    -0.17566     0.078852   -0.36216\n",
            " -0.11829    -0.83336002  0.11917    -0.16605     0.061555   -0.012719\n",
            " -0.56623     0.013616    0.22851001 -0.14396    -0.067549   -0.38157001\n",
            " -0.23698001 -1.70369995 -0.86691999 -0.26704001 -0.25889999  0.1767\n",
            "  3.86759996 -0.1613     -0.13273001 -0.68880999  0.18444     0.0052464\n",
            " -0.33873999 -0.078956    0.24185     0.36576    -0.34727001  0.28483\n",
            "  0.075693   -0.062178   -0.38988     0.22902    -0.21617    -0.22562\n",
            " -0.093918   -0.80374998]\n",
            "is word embedding: [ 6.18499994e-01  6.42539978e-01 -4.65519994e-01  3.75699997e-01\n",
            "  7.48380005e-01  5.37389994e-01  2.22390005e-03 -6.05769992e-01\n",
            "  2.64079988e-01  1.17030002e-01  4.37220007e-01  2.00920001e-01\n",
            " -5.78589998e-02 -3.45889986e-01  2.16639996e-01  5.85730016e-01\n",
            "  5.39189994e-01  6.94899976e-01 -1.56179994e-01  5.58300018e-02\n",
            " -6.05149984e-01 -2.89970011e-01 -2.55939998e-02  5.55930018e-01\n",
            "  2.53560007e-01 -1.96120000e+00 -5.13809979e-01  6.90959990e-01\n",
            "  6.62460029e-02 -5.42239994e-02  3.78710008e+00 -7.74030030e-01\n",
            " -1.26890004e-01 -5.14649987e-01  6.67050034e-02 -3.29329997e-01\n",
            "  1.34829998e-01  1.90490007e-01  1.38119996e-01 -2.15030000e-01\n",
            " -1.65730007e-02  3.12000006e-01 -3.31889987e-01 -2.60010008e-02\n",
            " -3.82030010e-01  1.94030002e-01 -1.24660000e-01 -2.75570005e-01\n",
            "  3.08990002e-01  4.84970003e-01]\n",
            "women word embedding: [-0.95897001  0.86149001 -0.53064001 -0.19908001  0.42945001  0.93177003\n",
            "  0.067319   -0.21413     0.39488    -0.53561002  0.42881    -1.33340001\n",
            " -0.038192   -0.15667     0.94351    -0.21873    -0.15586001  0.084439\n",
            " -0.058604   -0.55145001 -0.53280997  1.24339998  0.63441002  0.79233998\n",
            "  0.0097936  -1.71239996 -0.77291    -1.00240004 -0.69471997 -0.50487\n",
            "  3.05170012  1.49810004 -0.32957    -0.53871    -0.21201    -0.14259\n",
            " -0.02706     0.58579999 -0.56642002 -0.55984002 -0.60904998 -0.57062\n",
            "  1.33379996  0.67097002  1.06429994 -0.4181     -0.44273001 -1.0158\n",
            " -0.35795    -0.31110999]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo se utiliza esta matriz?. Se utiliza en la primera capa del modelo, es decir, en la capa Embedding. La matriz se le pasa al parámetro **weights**.\n",
        "                     \n",
        "\n",
        "```\n",
        "# Capa embeddings\n",
        "model.add(Embedding(NUM_WORDS, EMBED_SIZE, \n",
        "                        input_length=MAX_LEN,\n",
        "                        weights=[embedding_matrix]))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iEa9VWeu14Qa"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
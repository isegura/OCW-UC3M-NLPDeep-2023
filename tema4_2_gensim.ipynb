{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/OCW-UC3M-NLPDeep-2023/blob/main/tema4_2_gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA66S9V1H8T6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\" width=50%/>\n",
        "\n",
        "<h1><font color='#12007a'>Procesamiento de Lenguaje Natural con Aprendizaje Profundo</font></h1>\n",
        "<p>Autora: Isabel Segura Bedmar</p>\n",
        "\n",
        "<img align='right' src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op-cuN5XFqdB"
      },
      "source": [
        "# 4.2. Cómo usar modelos de word embeddings con la librería Gensim.\n",
        "\n",
        "**Gensim** (https://radimrehurek.com/gensim/) es una de las librerías de Python más populares para entrenar modelos de word embeddings y también para utilizar dichos modelos para la representación de textos y estimar la similitud entre ellos.\n",
        "\n",
        "En este ejercicio, aprenderemos a cargar un modelo de word embeddings utilizando dicha la librería y también estudiaremos las principales funcionalidades que ofrecen los modelos de word embeddings.\n",
        "\n",
        "El primer paso será instalar la librería:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gensim"
      ],
      "metadata": {
        "id": "jsihcMMBrINQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque es posible cargar un modelo de word embeddings desde una url o desde nuestra unidad de google drive, Gensim ya proporciona una lista de modelos de word embeddings que pueden ser descargados con la librería. Para consultar la lista de modelos disponibles ejecuta la siguiente celda:"
      ],
      "metadata": {
        "id": "7XudePvrrSf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "print(list(gensim.downloader.info()['models'].keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gJwpKwIrOI7",
        "outputId": "26400f62-b205-4da3-fce4-97ab0f4f92be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku6NHQvcP1Ed"
      },
      "source": [
        "## Cómo cargar un modelo del repositorio de Gensim\n",
        "\n",
        "Vamos a cargar el modelo **glove-wiki-gigaword-50**, un modelo Glove que fue entrenado con textos de Wikipedia y con GigaWord. La dimensión de los vectores es 50.\n",
        "El tamaño del modelo es de unos 66 MB. El tamaño de su vocabulario es 400.000 (palabras distintas)\n",
        "\n",
        "En este link, https://github.com/RaRe-Technologies/gensim-data, puedes consultar información sobre estos modelos.\n",
        "\n",
        "\n",
        "La operación puede tardar unos minutos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JpTYY4SrP4O8"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBxhpjI4Py9J"
      },
      "source": [
        "Vamos a consultar el vector (embedding) asociado a una palabra concreta, por ejemplo, 'mother'. Además, comprobamos que la dimensión es 50.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YVr-IPpnQHvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16e1b04-f15b-4f20-d05c-f81904c23e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50,)\n",
            "[ 0.4336     1.0727    -0.6196    -0.80679    1.2519     1.3767\n",
            " -0.93533    0.76088   -0.0056654 -0.063649   0.30297    0.52401\n",
            "  0.2843    -0.38162    0.98797    0.093184  -1.1464     0.070523\n",
            "  0.58012    0.50644   -0.24026    1.7344     0.020735   0.43704\n",
            "  1.2148    -2.2483    -0.41168   -0.24922    0.31225   -0.49464\n",
            "  2.0441    -0.012111  -0.19556    0.085665   0.27682    0.015702\n",
            "  0.0067683  0.12759    0.87008   -0.40641   -0.21057    0.41651\n",
            " -0.021812  -0.53649    0.54095   -0.43442   -0.52489   -2.0277\n",
            "  0.13136    0.11704  ]\n"
          ]
        }
      ],
      "source": [
        "vector = model['mother']\n",
        "print(vector.shape)\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6d-YCXzHLzi"
      },
      "source": [
        "## Métodos más útiles en un modelo de word embeddings\n",
        "\n",
        "### similarity\n",
        "El modelo dispone de un método **similarity** para calcular la similitud entre dos palabras. Si el resultado es cercano a 1, significa que ambas palabras son sinónimos o tienen un significado similar. Si el valor es próximo a 0, significa que las palabras no guardan ninguna relación.\n",
        "\n",
        "En la siguiente celda, calculamos la similitud entre la palabra *mother* y las palabras *father*, *mothers*, *woman*, *teeth*, *pen*.\n",
        "Fijate en sus resultados, ¿son coherentes con los significados de las palabras?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word1='mother'\n",
        "\n",
        "for word2 in ['father', 'mothers', 'woman', 'teeth', 'pen']:\n",
        "    similarity = model.similarity(word1, word2)\n",
        "    print(\"similarity({}, {}) = {}\".format(word1,word2,similarity))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdc5z6OYtuYZ",
        "outputId": "ad2887c2-1a83-4e3f-f6f6-eb536354813b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity(mother, father) = 0.8909038305282593\n",
            "similarity(mother, mothers) = 0.6945824027061462\n",
            "similarity(mother, woman) = 0.876370370388031\n",
            "similarity(mother, teeth) = 0.29342857003211975\n",
            "similarity(mother, pen) = 0.27105677127838135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PDLv51_vHacn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d34482-9800-440a-ee2e-79de902b281d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity of man and woman = 0.8860337734222412\n",
            "similarity of man and guy = 0.7553611397743225\n",
            "similarity of man and boy = 0.8564432263374329\n"
          ]
        }
      ],
      "source": [
        "word1='man'\n",
        "for word2 in ['woman', 'guy', 'boy']:\n",
        "    similarity = model.similarity(word1, word2)\n",
        "    print(\"similarity of {} and {} = {}\".format(word1,word2,similarity))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9txV2y9ID9g"
      },
      "source": [
        "### most_similar\n",
        "\n",
        "Otro método interesantes es **most_similar**, que recibe una palabra y nos devuelve una lista con las palabras más similares (más próximas en el modelo) ordenadas de mayor a menor similitud. Prueba con varias palabras distintas, por ejemplo, 'truck', 'car', 'aspirin', 'movile', 'computer', etc. ¿Qué opinas de los resultados?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cvIIWPnMVTU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5919f821-08d8-47df-f756-78263b193e75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('daughter', 0.9456227421760559),\n",
              " ('wife', 0.9426491856575012),\n",
              " ('grandmother', 0.9338483810424805),\n",
              " ('husband', 0.9062185287475586),\n",
              " ('father', 0.8909037709236145),\n",
              " ('sister', 0.8907995820045471),\n",
              " ('her', 0.879142165184021),\n",
              " ('woman', 0.876370370388031),\n",
              " ('aunt', 0.8758132457733154),\n",
              " ('friend', 0.8599086999893188)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.most_similar('mother')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_nh5l5FI1va"
      },
      "source": [
        "El método **most_similar** acepta como entrada una palabra pero puede recibir también una lista de vectores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gJWvQC6OIpdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435b20ea-1638-47da-c443-0ee40d0ba394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('good', 0.9492380023002625),\n",
              " ('bad', 0.946256697177887),\n",
              " ('really', 0.9346767663955688),\n",
              " ('little', 0.9166814684867859),\n",
              " ('too', 0.9116061329841614),\n",
              " ('something', 0.906011700630188),\n",
              " ('thing', 0.9056459665298462),\n",
              " (\"'re\", 0.9015171527862549),\n",
              " ('things', 0.9001196622848511),\n",
              " ('sure', 0.8996474742889404)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vector1=model['bad']\n",
        "vector2=model['good']\n",
        "\n",
        "model.most_similar([vector1, vector2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector1=model['law']\n",
        "vector2=model['judge']\n",
        "\n",
        "model.most_similar([vector1, vector2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeJFcc3jFR6J",
        "outputId": "94329715-b7f3-4400-a952-588c92351bdd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('law', 0.917686939239502),\n",
              " ('judge', 0.9152601361274719),\n",
              " ('court', 0.8893500566482544),\n",
              " ('justice', 0.8721724152565002),\n",
              " ('attorney', 0.8343154191970825),\n",
              " ('supreme', 0.8212406635284424),\n",
              " ('appeals', 0.8181477189064026),\n",
              " ('argued', 0.8140687942504883),\n",
              " ('lawyer', 0.809566080570221),\n",
              " ('case', 0.8033391237258911)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuZMqT8lJFsR"
      },
      "source": [
        "### similar_by_word\n",
        "\n",
        "El método **similar_by_word** es muy similar al método anterior, *most_similar*.\n",
        "\n",
        "La única diferencia es que **similar_by_word** únicamente tiene un argumento y debe ser siempre una palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UVoiUSGAQaHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d82ada4-c9a4-4e06-dc12-711a165feccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('car', 0.9208584427833557)\n",
            "('vehicle', 0.8651285767555237)\n",
            "('trucks', 0.8634739518165588)\n",
            "('tractor', 0.8452333807945251)\n",
            "('parked', 0.8431485891342163)\n",
            "('cars', 0.8306795358657837)\n",
            "('bus', 0.8230665326118469)\n",
            "('vehicles', 0.8144659399986267)\n",
            "('jeep', 0.814045786857605)\n",
            "('pickup', 0.805120050907135)\n"
          ]
        }
      ],
      "source": [
        "result = model.similar_by_word(\"truck\")\n",
        "for r in result:\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC2fVQwoJWhr"
      },
      "source": [
        "### distance\n",
        "\n",
        "El método **distance** devuelve la distancia del coseno entre dos palabras.\n",
        "\n",
        "En realidad, **similarity** es 1 menos la distancia del coseno: $similarity = 1 - distance = 1 - cosine$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WwZmM9z0Qu50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d33c65-7c5f-43a6-8c2f-d4006d0db8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.distance(woman, woman) = 0.0\n",
            "model.similarity(woman, woman) = 1.0\n"
          ]
        }
      ],
      "source": [
        "w1=\"woman\"\n",
        "d = f\"{model.distance(w1,w1):.1f}\"\n",
        "s = f\"{model.similarity(w1,w1):.1f}\"\n",
        "print(\"model.distance({}, {}) = {}\".format(w1,w1,d))\n",
        "print(\"model.similarity({}, {}) = {}\".format(w1,w1,s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zzLpuG95SFms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d723bb2c-7cd6-4e51-ce12-97c5b6f9c384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.distance(woman, ship) = 0.6\n",
            "model.similarity(woman, ship) = 0.4\n"
          ]
        }
      ],
      "source": [
        "w1=\"woman\"\n",
        "w2=\"ship\"\n",
        "d = f\"{model.distance(w1,w2):.1f}\"\n",
        "s = f\"{model.similarity(w1,w2):.1f}\"\n",
        "\n",
        "print(\"model.distance({}, {}) = {}\".format(w1,w2,d))\n",
        "print(\"model.similarity({}, {}) = {}\".format(w1,w2,s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fk3YRaLUSIse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c369029-3c72-406e-f1b2-dacacb6a481d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman math -> distancia: 0.8 similitud: 0.2\n",
            "woman car -> distancia: 0.5 similitud: 0.5\n",
            "woman girl -> distancia: 0.1 similitud: 0.9\n",
            "woman wife -> distancia: 0.2 similitud: 0.8\n"
          ]
        }
      ],
      "source": [
        "w1= 'woman'\n",
        "for w2 in ['math', 'car', 'girl', 'wife']:\n",
        "    d = model.distance(w1,w2)\n",
        "    s = model.similarity(w1,w2)\n",
        "    print(w1, w2, '-> distancia:', f\"{d:.1f}\", 'similitud:', f\"{s:.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKwsqynqyPhI"
      },
      "source": [
        "###doesnt_match\n",
        "\n",
        "El método **doesnt_match** es capaz de identificar en un conjunto de palabras la palabra que no encaja con el resto de palabras:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xRmZQRKtUGCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949ea858-24b6-45ee-e356-42e1900dea84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car\n"
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match(['computer', 'car', 'laptop', 'mobile']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8WYb_ZgeUHuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141c94a4-13fe-4b91-9679-904ab2305e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ship\n"
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match(\"orange ship apple sugar\".split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYQja5X0yIJW"
      },
      "source": [
        "###n_similarity\n",
        "\n",
        "El método **n_similarity** calcula la similitud entre dos conjuntos de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2-JJV7QJT3TO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd30810d-3249-4358-aa37-013ae0e8a4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3749\n"
          ]
        }
      ],
      "source": [
        "similarity = model.n_similarity(['math', 'car'], ['mexican', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wfkfHNxFT0iN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96389c72-f35a-48cb-e89e-af7f8bf00280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7059\n"
          ]
        }
      ],
      "source": [
        "similarity = model.n_similarity(['sushi', 'bar', 'fish'], ['mexican', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XPeWROHTT89U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cdc90c-dace-43cf-e111-4b6d99570d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8416\n"
          ]
        }
      ],
      "source": [
        "similarity = model.n_similarity(['sushi', 'red'], ['blue', 'restaurant'])\n",
        "print(f\"{similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfmCph3pU2sh"
      },
      "source": [
        "### most_similar_cosmul\n",
        "El  método **most_similar_cosmul** recibe una lista de palabras y devuelve una lista de palabras similares, pero con significado opuesto a otro conjunto de palabras:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PDWvm-4aQDv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21ed061-a023-401a-e0a4-68ee7cac5b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen: 0.9289\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])\n",
        "\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q1NO4DZXUfNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a638cc-09ad-4ebb-bb5d-6f524d16ef7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paris: 0.9397\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar_cosmul(positive=['madrid', 'france'], negative=['spain'])\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-yZF7P1UUuVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4d08e3-da1d-4645-a58b-c32a68d28822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bihac: 0.9868\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar_cosmul(positive=['baghdad', 'england'], negative=['london'])\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pautUMgxVpRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3197727-586b-4e7f-d943-6d20c9db5dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "portugal: 0.9569\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar_cosmul(positive=['spain', 'barcelona'], negative=['madrid'])\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Td0nKnS6P95m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e85aec4-2a18-4513-e95d-cb93dba7c866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "niece: 0.9162\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['woman', 'nephew'], negative=['man'])\n",
        "most_similar_key, similarity = result[0]\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSpbZmKnLDL6"
      },
      "source": [
        "## Word Mover's Distance (WMD): utilidad para obtener la similitud entre textos.\n",
        "\n",
        "Es una herramienta que nos permite obtener la similitud entre dos textos.\n",
        "\n",
        "\n",
        "https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "olvlq1fuSvJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d461f02e-690e-4876-cb2a-82ba5d140d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5629\n",
            "0.3508\n",
            "0.2121\n"
          ]
        }
      ],
      "source": [
        "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
        "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
        "sentence_president3 = 'The president greets the media in Illinois'.lower().split()\n",
        "\n",
        "distance = model.wmdistance(sentence_obama, sentence_president)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(sentence_obama, sentence_president3)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(sentence_president, sentence_president3)\n",
        "print(f\"{distance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GUn9esFiTaHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff0c0ba-9152-4798-9c4f-da70fc4b298a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0000\n",
            "0.1448\n",
            "0.6308\n"
          ]
        }
      ],
      "source": [
        "text1 = 'The hotel was very expensive and not good'.lower().split()\n",
        "text2 = 'The hotel was very good and not expensive'.lower().split()\n",
        "text3 = 'The hotel was very bad and not cheap'.lower().split()\n",
        "text4 = 'The best result was achieved by BERT'.lower().split()\n",
        "\n",
        "distance = model.wmdistance(text1, text2)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(text1, text3)\n",
        "print(f\"{distance:.4f}\")\n",
        "\n",
        "distance = model.wmdistance(text1, text4)\n",
        "print(f\"{distance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar un modelos desde local\n",
        "\n",
        "En este ejercicio, hemos trabajado con un modelos pre-entrenado proporcionado por Gensim. También sería posible cargar otro modelo almacenado en una url o en nuestra unidad de google drive.\n"
      ],
      "metadata": {
        "id": "CALhkCEOPcwC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQw2G9vWGqTj"
      },
      "source": [
        "\n",
        "También es posible cargar un modelo desde local. Por ejemplo, vamos a salvar el modelo anterior en un fichero llamado *mymodel.bin*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Lt9BZpB7GtyL"
      },
      "outputs": [],
      "source": [
        "model.save('mymodel.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes comprobar en Archivos asociados a este notebook, que en efecto, se ha almacenado dicho modelo.\n",
        "\n",
        "Ahora podríamos cargarlo directamente usando la clase **KeyedVectors** y su método **load**, que recibe como argumento la ruta donde está almacenado el modelo"
      ],
      "metadata": {
        "id": "E0PwrbEu19qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "new_model = KeyedVectors.load('mymodel.bin')\n"
      ],
      "metadata": {
        "id": "0uk95w-61wvl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a consultar su tamaño:"
      ],
      "metadata": {
        "id": "c_KXOL8j2R__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(new_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGfsiu5P2Rf_",
        "outputId": "0fc5e6a3-0bea-4a7e-841b-03fb7b3fcd62"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a descargar un modelo de word embeddings y lo vamos a guardar en nuestra unidad de google drive. Por ejemplo, puedes descargar uno de los modelos más populares de word embeddings: GoogleNews-vectors-negative300.bin.\n",
        "\n",
        "Añadelo a tu disco de Google Drive, en la carpeta 'Colab Notebooks'.\n",
        "Monta tu unidad de google drive, y modifica tu directorio de trabajo actual a '/content/drive/My Drive/Colab Notebooks/'.\n",
        "\n"
      ],
      "metadata": {
        "id": "h5dxbTMM2dWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/')\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G83Zcnf63ak6",
        "outputId": "fc4e48bd-0988-442d-cab7-93cdadbe9159"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "data\t\t\t\t       mymodel.bin\n",
            "docencia\t\t\t       mymodel.bin.vectors.npy\n",
            "GoogleNews-vectors-negative300.bin     proyectos\n",
            "GoogleNews-vectors-negative300.bin.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga ahora el modelo (tardará unos minutos):"
      ],
      "metadata": {
        "id": "9i2oG1CzXoB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n"
      ],
      "metadata": {
        "id": "lTm-gKplLNh4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a mostrar el tamaño del vocabulario"
      ],
      "metadata": {
        "id": "XKfQreijYEs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word_vectors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZPQJW5DUHac",
        "outputId": "9d517186-9461-441d-cb12-ec2f2bbedad2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos el modelo para mostrar las palabras más similares al adjetivo 'bad'. Podemos ver que sorprendentmente, devuelve 'good' como la primera palabra más próxima, con mayor similitud. Sin embargo, 'good' y 'bad' son antónimos!!!.\n",
        "\n",
        "¿Por qué crees que ocurre esto?. Esto ocurre porque 'bad' y 'good' son adjetivos que van a ocurrir en contextos muy similares (\"This movie is very good\" \"This movie is very bad\"). Los modelos de word embeddings utilizan la información de contexto para inferir los vectores de las palabras. Por ese motivo, 'good' y 'bad' tendrán un vector similar, aunque sus significados sean completamente distintos.\n"
      ],
      "metadata": {
        "id": "TGNdr8eHYRY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.similar_by_word(\"bad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM-0iltlYHwE",
        "outputId": "aa0749e2-89f1-4a2c-f7b8-c1b6b40a4ae0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('good', 0.7190051674842834),\n",
              " ('terrible', 0.6828612089157104),\n",
              " ('horrible', 0.6702597737312317),\n",
              " ('Bad', 0.669891893863678),\n",
              " ('lousy', 0.6647640466690063),\n",
              " ('crummy', 0.567781925201416),\n",
              " ('horrid', 0.5651682615280151),\n",
              " ('awful', 0.5527253150939941),\n",
              " ('dreadful', 0.5526429414749146),\n",
              " ('horrendous', 0.5445998311042786)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
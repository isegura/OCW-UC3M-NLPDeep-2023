{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\"/>\n",
        "\n",
        "<img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center> "
      ],
      "metadata": {
        "id": "1CG8uqYX6j6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Random Field for NER"
      ],
      "metadata": {
        "id": "B034cSmtrVc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please, download the following dataset: \n",
        "\n",
        "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus#ner_dataset.csv\n"
      ],
      "metadata": {
        "id": "wR0Xz-Wp6eFT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LGVaDj6PupB"
      },
      "source": [
        "\n",
        "https://www.aitimejournal.com/@akshay.chavan/complete-tutorial-on-named-entity-recognition-ner-using-python-and-keras\n",
        "\n",
        "\n",
        "In NLP, NER is a method of extracting the relevant information from a large corpus and classifying those entities into predefined categories such as location, organization, name and so on. This is a simple example and one can come up with complex entity recognition related to domain-specific with the problem at hand.\n",
        "\n",
        "<img src='https://d2ueix13hy5h3i.cloudfront.net/wp-content/uploads/2019/06/3.png' width=800>\n",
        "\n",
        "In this tutorial, we will use the following dataset\n",
        "\n",
        "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus#ner_dataset.csv\n",
        "\n",
        "This dataset is extracted from GMB(Groningen Meaning Bank) corpus which is tagged, annotated and built specifically to train the classifier to predict named entities such as name, location, etc.\n",
        "All the entities are labeled using the BIO scheme, where each entity label is prefixed with either B or I letter. B- denotes the beginning and I- inside of an entity. The words which are not of interest are labeled with 0 – tag.\n",
        "\n",
        "<img src='https://d2ueix13hy5h3i.cloudfront.net/wp-content/uploads/2019/06/Capture1.png' width=350>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This notebook needs to downgrade the version of scikit-learn, to be compatible with the library sklearn-crfsuite, which is a CRFsuite (python-crfsuite) wrapper which provides scikit-learn-compatible sklearn_crfsuite.CRF estimator.\n"
      ],
      "metadata": {
        "id": "owc7TYNbGBP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/TeamHG-Memex/sklearn-crfsuite/issues/60\n",
        "!pip install -U 'scikit-learn<0.24'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G03dI_Z1F-zR",
        "outputId": "119ab6c0-71af-4bba-deaa-23a0e3dcc488"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn<0.24 in /usr/local/lib/python3.9/dist-packages (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<0.24) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<0.24) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<0.24) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sklearn-crfsuite\n"
      ],
      "metadata": {
        "id": "InOa-08KGQ3W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite.metrics import flat_f1_score\n",
        "from sklearn_crfsuite.metrics import flat_classification_report"
      ],
      "metadata": {
        "id": "ARnjXRZBAqN8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_1v6O2zTGK_"
      },
      "source": [
        "Before to load the dataset, we need to mount our folder in google drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05N_SwgGTL6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3431cfe-1039-4b14-f2e1-68955f9ad4ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "PATH = \"/content/drive/My Drive/Colab Notebooks/data/ner/\"\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq4pH_wOU1lz"
      },
      "source": [
        "\n",
        "## Loading the dataset\n",
        "\n",
        "Now, we can load the dataset. Sentence # indicates the sentence number and each sentence comprises of words that are labeled using the BIO scheme in the tag column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYF3qJjxTsH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "1d0440b0-30f9-45f1-e69b-06e3e00aacb0"
      },
      "source": [
        "import pandas as pd\n",
        "path_data=PATH+'ner_dataset.csv'\n",
        "\n",
        "#Reading the csv file\n",
        "df = pd.read_csv(path_data, encoding = \"ISO-8859-1\")\n",
        "print(df.head(15))\n",
        "print()\n",
        "print('some statistics about the dataset:')\n",
        "df.describe()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sentence #           Word  POS    Tag\n",
            "0   Sentence: 1      Thousands  NNS      O\n",
            "1           NaN             of   IN      O\n",
            "2           NaN  demonstrators  NNS      O\n",
            "3           NaN           have  VBP      O\n",
            "4           NaN        marched  VBN      O\n",
            "5           NaN        through   IN      O\n",
            "6           NaN         London  NNP  B-geo\n",
            "7           NaN             to   TO      O\n",
            "8           NaN        protest   VB      O\n",
            "9           NaN            the   DT      O\n",
            "10          NaN            war   NN      O\n",
            "11          NaN             in   IN      O\n",
            "12          NaN           Iraq  NNP  B-geo\n",
            "13          NaN            and   CC      O\n",
            "14          NaN         demand   VB      O\n",
            "\n",
            "some statistics about the dataset:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Sentence #     Word      POS      Tag\n",
              "count         47959  1048575  1048575  1048575\n",
              "unique        47959    35178       42       17\n",
              "top     Sentence: 1      the       NN        O\n",
              "freq              1    52573   145807   887908"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bb76fb2-8312-4fe4-b329-5d57bd6a2f8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47959</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bb76fb2-8312-4fe4-b329-5d57bd6a2f8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bb76fb2-8312-4fe4-b329-5d57bd6a2f8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bb76fb2-8312-4fe4-b329-5d57bd6a2f8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Observations :\n",
        "- There are total 47,959 sentences in the dataset.\n",
        "- Number unique words in the dataset are 35,178.\n",
        "- Total 17 labels (Tags).\n"
      ],
      "metadata": {
        "id": "N4i4wahjD2Ag"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKUZVyNLVn2q"
      },
      "source": [
        "Let us to show the set of tags, which are the classes to classify the tokens based on the IOB schema:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUsyyVOGVz6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7d62da-9255-4e4e-b835-96091316b4ce"
      },
      "source": [
        "##Displaying the unique Tags\n",
        "df['Tag'].unique()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omW6xm1_bKSR"
      },
      "source": [
        "There are lots of missing values in 'Sentence #' attribute. So we will use pandas fillna technique and use 'ffill' method which propagates last valid observation forward to next.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1zGQUhKbCyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22073c8d-1c0f-4598-f890-891fba4a70fd"
      },
      "source": [
        "\n",
        "#Checking null values, if any.\n",
        "df.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas dataframe.ffill() function is used to fill the missing value in the dataframe. ‘ffill’ stands for ‘forward fill’ and will propagate last valid observation forward."
      ],
      "metadata": {
        "id": "0AMaro9ZBRmw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoEZ2PaubICR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cab9cfe9-6c87-4f25-c51a-0c81afa41abb"
      },
      "source": [
        "df = df.fillna(method = 'ffill')\n",
        "df.head(100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1   Sentence: 1             of   IN      O\n",
              "2   Sentence: 1  demonstrators  NNS      O\n",
              "3   Sentence: 1           have  VBP      O\n",
              "4   Sentence: 1        marched  VBN      O\n",
              "..          ...            ...  ...    ...\n",
              "95  Sentence: 5             's  POS      O\n",
              "96  Sentence: 5         ruling  VBG      O\n",
              "97  Sentence: 5          Labor  NNP  B-org\n",
              "98  Sentence: 5          Party  NNP  I-org\n",
              "99  Sentence: 5             in   IN      O\n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9386cec-8fb0-46ab-91e8-07d0160463c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>ruling</td>\n",
              "      <td>VBG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Labor</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Party</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9386cec-8fb0-46ab-91e8-07d0160463c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9386cec-8fb0-46ab-91e8-07d0160463c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9386cec-8fb0-46ab-91e8-07d0160463c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NER can be viewed as a classification task at token level. That is, the goal is to classify each token in the input sequence with one of the classes {'O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
        "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
        "       'I-eve', 'I-nat'}.\n",
        "\n",
        "Therefore, we will have to represent each token to classify as a set of features. "
      ],
      "metadata": {
        "id": "citpqPf20Ccd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-qMyDtgcKu"
      },
      "source": [
        "We define a class to represent a sentence. Each sentence is represented by a list of triples. Each triple represetns a token with its PoS tag and its tag (IOB tag)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_fEoMNCbPxr"
      },
      "source": [
        "class Sentences(object):\n",
        "    def __init__(self, df):\n",
        "        self.n_sent = 1\n",
        "        self.df = df\n",
        "        self.empty = False\n",
        "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
        "                                                       s['POS'].values.tolist(),\n",
        "                                                       s['Tag'].values.tolist())]\n",
        "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "        \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent +=1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIoy-HdrbTi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf98160-cc7d-4fcf-e793-cfa1fc3353b2"
      },
      "source": [
        "#Displaying one full sentence\n",
        "getter = Sentences(df)\n",
        "# rebuild the texts of sentences\n",
        "text_sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
        "print(text_sentences[0])\n",
        "\n",
        "i = 0\n",
        "# show the tokens...\n",
        "while i < 3:\n",
        "    print(\"Sentence : \", i, getter.get_next())\n",
        "    i += 1\n",
        "\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
            "Sentence :  0 [('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n",
            "Sentence :  1 [('Families', 'NNS', 'O'), ('of', 'IN', 'O'), ('soldiers', 'NNS', 'O'), ('killed', 'VBN', 'O'), ('in', 'IN', 'O'), ('the', 'DT', 'O'), ('conflict', 'NN', 'O'), ('joined', 'VBD', 'O'), ('the', 'DT', 'O'), ('protesters', 'NNS', 'O'), ('who', 'WP', 'O'), ('carried', 'VBD', 'O'), ('banners', 'NNS', 'O'), ('with', 'IN', 'O'), ('such', 'JJ', 'O'), ('slogans', 'NNS', 'O'), ('as', 'IN', 'O'), ('\"', '``', 'O'), ('Bush', 'NNP', 'B-per'), ('Number', 'NN', 'O'), ('One', 'CD', 'O'), ('Terrorist', 'NN', 'O'), ('\"', '``', 'O'), ('and', 'CC', 'O'), ('\"', '``', 'O'), ('Stop', 'VB', 'O'), ('the', 'DT', 'O'), ('Bombings', 'NNS', 'O'), ('.', '.', 'O'), ('\"', '``', 'O')]\n",
            "Sentence :  2 [('They', 'PRP', 'O'), ('marched', 'VBD', 'O'), ('from', 'IN', 'O'), ('the', 'DT', 'O'), ('Houses', 'NNS', 'O'), ('of', 'IN', 'O'), ('Parliament', 'NN', 'O'), ('to', 'TO', 'O'), ('a', 'DT', 'O'), ('rally', 'NN', 'O'), ('in', 'IN', 'O'), ('Hyde', 'NNP', 'B-geo'), ('Park', 'NNP', 'I-geo'), ('.', '.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSAdqfG7bhex"
      },
      "source": [
        "## Feature Preparation\n",
        "To represent each token, we will use the most common feature set for the NER Task. That is, the contextual information of the tokens around the token that you are representing. \n",
        "In particular, we use a window of size 1 around the token to be represented. \n",
        "For each token, we will use the following features:\n",
        "- lowercase word\n",
        "- suffixes of lenght 2 and 3.\n",
        "- issuper(): boolean indicating if the word's characteres are in uppercase. \n",
        "- istitle(): if the first letter is uppercase.\n",
        "- isdigit():\n",
        "- postag: morphological category.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBoMMBEybmkS"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],  # sufixe\n",
        "        'word[-2:]': word[-2:],  # sufixe\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5m2zBp3WgzV"
      },
      "source": [
        "X = [sent2features(s) for s in sentences]\n",
        "y = [sent2labels(s) for s in sentences]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXFKbq57cgVl"
      },
      "source": [
        "We must split the dataset to obtain training-test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL-sosyyWy41"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VePnO1kvcJFs"
      },
      "source": [
        "## CRF\n",
        "\n",
        "CRFs are used for predicting the sequences that use the contextual information to add information which will be used by the model to make a correct prediction.\n",
        "\n",
        "Below is the formula for CRF where y is the output variable and X is input sequence.\n",
        "\n",
        "\n",
        "\n",
        "<img src='https://d2ueix13hy5h3i.cloudfront.net/wp-content/uploads/2019/06/CodeCogsEqn1-6.png' width=500>\n",
        "\n",
        "\n",
        "\n",
        "The output sequence is modeled as the normalized product of the feature function.\n",
        "\n",
        "Some interesting sources about CRF:\n",
        "\n",
        "https://repository.upenn.edu/cis_papers/159/?ref=https://githubhelp.com\n",
        "\n",
        "https://www.sciencedirect.com/topics/computer-science/conditional-random-field\n",
        "\n",
        "https://www.youtube.com/watch?v=rc3YDj5GiVM\n",
        "\n",
        "https://www.aitimejournal.com/@akshay.chavan/introduction-to-conditional-random-fields-crfs\n",
        "\n",
        "https://towardsdatascience.com/conditional-random-fields-explained-e5b8256da776\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX-p2rA2gHjG"
      },
      "source": [
        "## Trainig the CRF model\n",
        "Now, we can train a model. This process can take several minutes....\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDh-9H_Fbyvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6059b0af-6649-45ba-d3b9-a842e28805ac"
      },
      "source": [
        "crf = CRF(algorithm = 'lbfgs',\n",
        "         c1 = 0.1,\n",
        "         c2 = 0.1,\n",
        "         max_iterations = 100,\n",
        "         all_possible_transitions = False)\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  warnings.warn('From version 0.24, get_params will raise an '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_transitions=False, c1=0.1, c2=0.1,\n",
              "    keep_tempfiles=None, max_iterations=100)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on the test dataset"
      ],
      "metadata": {
        "id": "MjgQDRcbzBY7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Da7CPWfb4n8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0bb8dd5-ff94-4f52-8756-7b72e29e821a"
      },
      "source": [
        "#Predicting on the test set.\n",
        "y_pred = crf.predict(X_test)\n",
        "\n",
        "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted')\n",
        "print(f1_score)\n",
        "\n",
        "report = flat_classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9711478612209549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.48      0.16      0.24        88\n",
            "       B-eve       0.41      0.37      0.39        52\n",
            "       B-geo       0.86      0.90      0.88      7489\n",
            "       B-gpe       0.97      0.94      0.96      3159\n",
            "       B-nat       0.68      0.44      0.53        39\n",
            "       B-org       0.80      0.75      0.77      4123\n",
            "       B-per       0.85      0.83      0.84      3334\n",
            "       B-tim       0.93      0.88      0.90      4113\n",
            "       I-art       0.45      0.07      0.11        76\n",
            "       I-eve       0.32      0.32      0.32        44\n",
            "       I-geo       0.83      0.80      0.82      1510\n",
            "       I-gpe       0.90      0.65      0.75        40\n",
            "       I-nat       0.75      0.38      0.50        16\n",
            "       I-org       0.80      0.80      0.80      3478\n",
            "       I-per       0.85      0.89      0.87      3447\n",
            "       I-tim       0.84      0.78      0.81      1273\n",
            "           O       0.99      0.99      0.99    176865\n",
            "\n",
            "    accuracy                           0.97    209146\n",
            "   macro avg       0.75      0.64      0.68    209146\n",
            "weighted avg       0.97      0.97      0.97    209146\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROPOSED EXERCISE: \n",
        "\n",
        "In the previous cells, we have used only the previous and next tokes of the token to be represented. \n",
        "\n",
        "1.   Increase the window size to 2. Does it improve the results?\n",
        "2.   Extend the feature set adding new features that can help you to improve the resutls. \n",
        "3. Train a new system to recognize drug names (https://github.com/isegura/DDIcorpus)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mg9xNesDPofV"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\"/>\n",
        "\n",
        "<img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>   "
      ],
      "metadata": {
        "id": "phoCz-kIU2-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipelines\n",
        "\n",
        "En este notebook, vamos a dar los primeros pasos para ver cómo podemos utilizar transformers para distintas tareas de PLN. \n",
        "\n",
        "HuggingFace proporciona muchos modelos pre-entrenados que ya están disponibles para ser utilizados directamente. \n",
        "\n",
        "Un **pipeline** es una aplicación que encapsula un modelo pre-entrenado y que permite utilizar dicho modelo de forma sencilla. \n",
        "La librería **transformer** proporciona una clase **Pipeline** que permite cargar un modelo pre-entrenado para una tareas de PLN específica como: clasificación de textos, análisis de sentimiento, reconocimiento de entidades, etc. \n",
        "\n"
      ],
      "metadata": {
        "id": "57QP70L45nJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: En este notebook, no es necesario utilizar GPU o TPU. "
      ],
      "metadata": {
        "id": "I941EJ5jVEHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer paso será instalar la librería de transformers:\n",
        "\n"
      ],
      "metadata": {
        "id": "pUo690-96Dgq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOvJ-Ob65kuK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación de textos\n",
        "\n",
        "El pipeline **text-classification** por defecto carga el modelo pre-entrenado 'distilbert-base-uncased-finetuned-sst-2-english', que fue entrenado sobre el corpus SST (análisis de sentimiento con dos clases)"
      ],
      "metadata": {
        "id": "EwqlDKWFdm-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\")\n",
        "classifier(\"The movie was very boring.\")\n"
      ],
      "metadata": {
        "id": "Kyboc-k6doh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "De hecho, ese mismo modelo se carga para el pipeline **sentiment-analysis**:"
      ],
      "metadata": {
        "id": "uAMOpYkd-MET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "print(classifier(\"The sandwich is deliciuous.\"))\n",
        "print(classifier(\"I've been waiting for a deep learning course my whole life.\"))\n",
        "print(classifier(\"This is the worst movie ever made.\"))"
      ],
      "metadata": {
        "id": "PRY3lo5I8mrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También se puede aplicar directamente sobre una lista de oraciones:"
      ],
      "metadata": {
        "id": "DdqyK0Gh51lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a deep learning course my whole life.\", \n",
        "     \"The food was delicious!!\",\n",
        "     \"This is the worst service we've ever had.\",\n",
        "     \"Today is Monday\",\n",
        "     \"Today is Friday\",\n",
        "     \"This restaurant is awesome.\", \n",
        "     \"The movie was very boring.\"]\n",
        ")"
      ],
      "metadata": {
        "id": "df2S7Q009ps1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También puedes cargar modelos específicos. Por ejemplo, como el modelo **cardiffnlp/twitter-xlm-roberta-base-sentiment**, un modelo RoBERTa pre-entrenado con tweets para la tarea de análisis sentimiento. \n",
        "Este modelo, y muchos otros, requieren la instalación **sentencepiece** (un tokenizador especial para redes neuronales)"
      ],
      "metadata": {
        "id": "YeAKvOBj4E_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "Dx9oDJZPUHYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
        "print(classifier(\"The hotel was excellent.\"))\n",
        "print(classifier(\"The movie was produced in Spain.\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8TQiTXO4Vgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot-classification \n",
        "El tarea de análisis de sentimiento es un problema de clasificación de texto, donde el objetivo es detectar la polaridad (positiva o negativa) de un texto. Sin embargo, existen otros muchos problemas de clasificación de texto como detección de spam, detección de noticias falsas, detección de mensajes de odio, detección de mensajes sexistas, etc. En cada problema, el conjunto de clases (etiquetas) puede ser diferente.\n",
        "\n",
        "El pipeline **zero-shot-classification** nos va a permitir clasificar cualquier tipo de texto, sin necesidad de entrenar el modelo con un conjunto de datos específico para la tarea. Únicamente es necesario especificar el conjunto de clases. El pipeline va a producir una probabilidad para cada una de las clases. "
      ],
      "metadata": {
        "id": "fe20Alw0nOdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline = pipeline(\"zero-shot-classification\")\n"
      ],
      "metadata": {
        "id": "0dxRMLZenZ9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ejemplo, podemos usar el pipelines para clasificar noticias:"
      ],
      "metadata": {
        "id": "jxllS5M_baEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"Elon Musk agreed in late April to buy Twitter for $54.20 per share\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\", \"health\"],\n",
        ")"
      ],
      "metadata": {
        "id": "LlZsqVSandc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"The U.S. government has ordered millions of doses of a vaccine that protects against monkeypox.\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\", \"health\"],\n",
        ")"
      ],
      "metadata": {
        "id": "rcqlrVhlbtE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También para detectar mensajes sexistas o racistas:"
      ],
      "metadata": {
        "id": "bVJz4RSnce31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"All Muslims are terrorists.\",\n",
        "    candidate_labels=[\"racism\", \"sexism\", \"neutral\"],\n",
        ")"
      ],
      "metadata": {
        "id": "HXILNJbSn0S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"Women drive badly unlike men.\",\n",
        "    candidate_labels=[\"racism\", \"sexism\", \"neutral\"],\n",
        ")"
      ],
      "metadata": {
        "id": "H39hsTrYo1yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La ideología de un tweet:"
      ],
      "metadata": {
        "id": "xRv58gp_czsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"El aborto es un asesinato.\",\n",
        "    candidate_labels=[\"derecha\", \"izquierda\", \"neutro\"],\n",
        ")"
      ],
      "metadata": {
        "id": "2EJzNmCfp2IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identificar noticias falses"
      ],
      "metadata": {
        "id": "UUjjwigZcX7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"The Earth is flat\",\n",
        "    candidate_labels=[\"fake\", \"non-fake\"],\n",
        ")"
      ],
      "metadata": {
        "id": "W-dSA4yigRUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo no siempre funciona correctamente!!!\n",
        "\n"
      ],
      "metadata": {
        "id": "aqBZ3XBBpd6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"Women are one half of society.\",\n",
        "    candidate_labels=[\"racism\", \"sexism\", \"neutral\"],\n",
        ")"
      ],
      "metadata": {
        "id": "W3pJMS44pVlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"Donald Trump is a left-wing politician\",\n",
        "    candidate_labels=[\"fake\", \"non-fake\"],\n",
        ")"
      ],
      "metadata": {
        "id": "IbpwNuEhniX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de noticia false (https://edition.cnn.com/2022/03/12/politics/fact-check-dicaprio-donation-10-million-ukraine/index.html)"
      ],
      "metadata": {
        "id": "JOc7M-3K72iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"Leonardo DiCaprio makes multiple donations to Ukraine\",\n",
        "    candidate_labels=[\"fake\", \"non-fake\"],\n",
        ")"
      ],
      "metadata": {
        "id": "PxtnNDcPfYmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pipeline(\n",
        "    \"All babies are precious! Life starts at conception! Pro-Life!.\",\n",
        "    candidate_labels=[\"right\", \"left\", \"neutral\"],\n",
        ")"
      ],
      "metadata": {
        "id": "z0od5rL8qjTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de textos\n",
        "\n",
        "Esta tarea consiste en producir texto nuevo. Son modelos útiles para tareas donde es necesario completar un texto o para tares como la generación de resúmenes, paráfrisis, etc. \n",
        "\n",
        "ChatGPT es un ejemplo de este tipo de modelo. Por ejemplo, es capaz de a partir de la descripción de un código, generar el código. \n",
        "\n",
        "Dentro de estos modelos, podemos distinguir dos tipos:\n",
        "- los que a partir de un texto, tratan de predecir la siguiente palabra. Los modelos GPT son de este tipo. \n",
        "- los que traducen un texto a otro (por ejemplo, generan un resumen). T5 o BART son algunos de los modelos más populares. \n",
        "\n",
        "HugginFace ya proporciona un pipeline que nos permite genera texto nuevo sin necesidad de entrenarlo sobre ningún corpus. En concreto, el pipeline recibe un texto y lo completa. \n",
        "\n"
      ],
      "metadata": {
        "id": "uxYqHA_5tdEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n"
      ],
      "metadata": {
        "id": "wDtQdHWytokc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text generation involves randomness, so the model will produce different outputs every time: "
      ],
      "metadata": {
        "id": "NxTcwcu8t2Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"Protest erupt in Greece\")\n"
      ],
      "metadata": {
        "id": "0avhafDAttb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can set the number of outputs and the maximum lenght of each sentence. \n"
      ],
      "metadata": {
        "id": "qE6QbcwhuVeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\n",
        "    \"once upon a time there was a little girl\",\n",
        "    max_length=20,\n",
        "    num_return_sequences=4,\n",
        ")"
      ],
      "metadata": {
        "id": "VGGBJ25QubEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos especificar el modelo que queremos utilizar para la tarea de generación (https://huggingface.co/models?pipeline_tag=text-generation)\n",
        "En este caso usaremos, el modelo distilgpt2:"
      ],
      "metadata": {
        "id": "5WcIye6nvUG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")"
      ],
      "metadata": {
        "id": "xs_CSqTPvnlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "id": "eBUEoLSrvo41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAmos a cargar un modelo para español:"
      ],
      "metadata": {
        "id": "41ine7u--UpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"DeepESP/gpt2-spanish\")"
      ],
      "metadata": {
        "id": "uK1oTGQrwJY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\n",
        "    \"El gobierno cree que la huelga será \",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "id": "1sT20jhgwWQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\n",
        "    \"Erase una pequeña niña\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "id": "nUZzt2xNwhEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mask-filling\n",
        "\n",
        "Otra tarea relacionada con la generación de textos, es la tarea capaz de inferir los huecos en una oración. El pipeline es **fill-mask**."
      ],
      "metadata": {
        "id": "W4zAxtoVw3Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline(\"fill-mask\")\n"
      ],
      "metadata": {
        "id": "nQ_L-1pwxKhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debemos utilizar el token especial  $<mask>$ para indicar qué huecos deben ser completado. El parámetro **top_k** indica cuántas posibilidades queremos recuperar:"
      ],
      "metadata": {
        "id": "BxtSVVK5xieU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"In this course, I will teach you how to develop <mask> models.\", top_k=5)"
      ],
      "metadata": {
        "id": "4AgSGgHnxN7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"There was a <mask> girl.\", top_k=2)"
      ],
      "metadata": {
        "id": "Ae_aiFjA2okj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver cómo funciona cuando hay varios huecos:"
      ],
      "metadata": {
        "id": "ghYriDm-fwWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"In this <mask>, I will teach you how to develop <mask> models.\", top_k=5)"
      ],
      "metadata": {
        "id": "liUuv3vofqJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconocimiento de entidades\n",
        "En inglés, Named Entity Recognition (NER). El objetivo es identifica menciones de personas, lugares y organizaciones. "
      ],
      "metadata": {
        "id": "T7au3aQg38qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", grouped_entities=True)\n"
      ],
      "metadata": {
        "id": "jyzsOZ5B4BE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner(\"My name is Isabel Segura. I work at Carlos III University of Madrid.\")\n"
      ],
      "metadata": {
        "id": "4ArI104n4EYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio:\n",
        "¿Qué efecto tiene grouped = False?"
      ],
      "metadata": {
        "id": "mZ9vtetG_eJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner(\"My name is Isabel. I work at Carlos III University of Madrid\", grouped_entities = False )\n"
      ],
      "metadata": {
        "id": "xMVP9o1S_lgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a cargar un modelo pre-entrenado para reconocer entidades en textos en español"
      ],
      "metadata": {
        "id": "TnkXKgWDhgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", model=\"mrm8488/bert-spanish-cased-finetuned-ner\",\n",
        "    tokenizer=('mrm8488/bert-spanish-cased-finetuned-ner',  {\"use_fast\": False}\n",
        "))\n"
      ],
      "metadata": {
        "id": "6eMBebXGg2fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"El PP sería primera fuerza en Sevilla y Granada\"\n",
        "ner(sentence, grouped_entities = True)"
      ],
      "metadata": {
        "id": "AZoY0cS3heWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"Moreno Bonilla necesitará a VOX para gobernar en Andalucía\"\n",
        "ner(sentence, grouped_entities = False)"
      ],
      "metadata": {
        "id": "UoRNTRdEhm52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question answering\n",
        "Este pipeline permite responder preguntas utilizando la información de un contexto: \n"
      ],
      "metadata": {
        "id": "0iEMx4PI4vgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n"
      ],
      "metadata": {
        "id": "EQKzFlB742MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Isabel and I work at Carlos III University of Leganés\",\n",
        ")"
      ],
      "metadata": {
        "id": "9bqV3g5V6HUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(\n",
        "    question=\"¿Cuál es la tasa de paro en España?\",\n",
        "    context=\"El paro de la eurozona repite el mínimo histórico del 6,8%, mientras España sigue en el 13,3%\",\n",
        ")"
      ],
      "metadata": {
        "id": "qzlqAMPlk2fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de resúmenes\n",
        "Genera un resúmen preciso y conciso para un texto:"
      ],
      "metadata": {
        "id": "kA5sgjcm6Wml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")"
      ],
      "metadata": {
        "id": "9VROCLfF46Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La generación del resumen puede tardar unos minutos:"
      ],
      "metadata": {
        "id": "V_J9JTpfY5fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        "\n",
        "summarizer(text)"
      ],
      "metadata": {
        "id": "jugQYsiB6iRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traducción automática\n",
        "\n",
        "Dado un texto en un idioma, el modelo genera su traducción a otro idioma. Es necesario instalar la librería **sentencepiece**\n"
      ],
      "metadata": {
        "id": "5IOaq7iT6ynI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation_en_to_fr\")\n",
        "translation = translator(text)\n",
        "\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "vUqJzcyBpmbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello my friends! How are you doing today?\"\n",
        "\n",
        "translator = pipeline(\"translation_en_to_de\")\n",
        "translation = translator(text)\n",
        "\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "3nGVFdlopWoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction\n",
        "Este pipeline te permite extraer los vectores que el modelo pre-entrenado asignaría a la oración de entrada. Por defecto, utiliza el modelo **distilbert-base-cased**, aunque podríamos probar con otro modelo. "
      ],
      "metadata": {
        "id": "iydb0TWwm_BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"Hello my friends\"\n",
        "#text = \"Hello my friends! How are you doing today?\"\n",
        "\n",
        "extractor = pipeline(\"feature-extraction\")\n",
        "vector=extractor(text)\n"
      ],
      "metadata": {
        "id": "w1uCr3K2oVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos la dimensión de la palabra (siempre es 768 en un modelo de Distilbert)\n",
        "\n"
      ],
      "metadata": {
        "id": "iQJ_-Wf1B4J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vector[0][0])) # should be 768\n",
        "\n",
        "assert len(vector[0][0]) == 768 # los vectores de las palabras tienen dimensión 768"
      ],
      "metadata": {
        "id": "bu-1vcmEo1fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para aumentar la información sobre pipelines, por favor, consulta la siguiente página https://huggingface.co/docs/transformers/main_classes/pipelines\n"
      ],
      "metadata": {
        "id": "xcxfPeken9C0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1: \n",
        "\n",
        "Prueba con el modelo **finiteautomata/beto-sentiment-analysis** para la tarea de análisis de sentimiento en español."
      ],
      "metadata": {
        "id": "IImrpLhDZ9zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "q2ZLbcXhakOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2: \n",
        "\n",
        "Crea un pipeline que te permita clasificar mensajes tóxicos en español en Twitter (busca el modelo en HuggingFace):"
      ],
      "metadata": {
        "id": "9BDaeIx9bI0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "9qRxU3cKbLf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3: \n",
        "Crea un pipeline que te permita clasificar mensajes de bulling en Twitter:"
      ],
      "metadata": {
        "id": "qfxQgNM5c2xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n"
      ],
      "metadata": {
        "id": "e2tbm3kXc8hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICA 1:\n",
        "\n",
        "Utilizar el pipeline de zero-classification para clasificar los mensajes del conjunto test de EXIST, tanto para la tarea de clasificaicón binaria, como para la tarea de muliclasificación.\n",
        "\n",
        "Cálcula las métricas y compara con los enfoques anteriores (SVM, CNN con y sin word embeddings, BiLSTM con y sin embeddings, etc). \n",
        "\n",
        "¿Cuál es el mejor modelo hasta el momento?\n",
        "\n"
      ],
      "metadata": {
        "id": "tB_M-YMS8K_w"
      }
    }
  ]
}
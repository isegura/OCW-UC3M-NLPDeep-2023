{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMpB4WCiOAksjwb40vHlkTT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c772978606ed46da89e25e569c20e29a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33ae62037c804e49b1b427a6c397b32f","IPY_MODEL_e1a2fd7ef56d4470b6e917987e6c619c","IPY_MODEL_b621da29cbe0463e830ddf1650a1f9f1"],"layout":"IPY_MODEL_de54be6ca6b44d64a8f9591f7c8ec55b"}},"33ae62037c804e49b1b427a6c397b32f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19fc60106ea94f72b87ddbc71ddffcd9","placeholder":"​","style":"IPY_MODEL_7bbc9322a83f4be0a3b37cba54285f40","value":" 50%"}},"e1a2fd7ef56d4470b6e917987e6c619c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_38e7132a92b14e7db00889124f91f952","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_984d7e02e522475fac50fc638f21aea4","value":1}},"b621da29cbe0463e830ddf1650a1f9f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e1606e7fcf64bf58802a569731b23e2","placeholder":"​","style":"IPY_MODEL_44eaf1c99cf841ffb983517e9adc7592","value":" 1/2 [00:03&lt;00:03,  3.08s/ba]"}},"de54be6ca6b44d64a8f9591f7c8ec55b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19fc60106ea94f72b87ddbc71ddffcd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bbc9322a83f4be0a3b37cba54285f40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38e7132a92b14e7db00889124f91f952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"984d7e02e522475fac50fc638f21aea4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e1606e7fcf64bf58802a569731b23e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44eaf1c99cf841ffb983517e9adc7592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f02ae431af34e48aa82762df714ee5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5891bfbe7e074d519f9836d9b803e448","IPY_MODEL_2c2992cb15d14fc5a257aee743a4ff5b","IPY_MODEL_0bbeb05101b8439ea6006e8e2471e239"],"layout":"IPY_MODEL_dbd70e16f0b5411c9dfd120abad17d05"}},"5891bfbe7e074d519f9836d9b803e448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ea873a529c6450ab60a71382d6c5176","placeholder":"​","style":"IPY_MODEL_1ca7597596f845508b3b9dd9e9e7f3d7","value":"  0%"}},"2c2992cb15d14fc5a257aee743a4ff5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b2533f732444a7e99827c3d46fd9948","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0b713f2173743bc99ca967bbcc2d2a5","value":0}},"0bbeb05101b8439ea6006e8e2471e239":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed1c3be4e48a4b02b858a4fe2c5759d0","placeholder":"​","style":"IPY_MODEL_83fc4ce02a354cceb24dee396f0e8514","value":" 0/1 [00:00&lt;?, ?ba/s]"}},"dbd70e16f0b5411c9dfd120abad17d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ea873a529c6450ab60a71382d6c5176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca7597596f845508b3b9dd9e9e7f3d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b2533f732444a7e99827c3d46fd9948":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b713f2173743bc99ca967bbcc2d2a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed1c3be4e48a4b02b858a4fe2c5759d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83fc4ce02a354cceb24dee396f0e8514":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"664f24aae2d1482f8f4b7d48593078d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4933b1910d014b378de0e9a303f6b372","IPY_MODEL_16f0414888264f459c767fc08522d8e4","IPY_MODEL_8da587deadd44c86b0bff900027bbc0d"],"layout":"IPY_MODEL_8323f1abe1ef430da6d5586e77b19c5b"}},"4933b1910d014b378de0e9a303f6b372":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b90c4c5a0da742b09f5010b882050d81","placeholder":"​","style":"IPY_MODEL_a2d68edb9e6f43899fe859576ad727ab","value":"  0%"}},"16f0414888264f459c767fc08522d8e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ea122e0b377435e95908562491c6032","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fae1579b95a4f7fb253596a8659e831","value":0}},"8da587deadd44c86b0bff900027bbc0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c7e3daca9b3426d808eb566e1abb8fe","placeholder":"​","style":"IPY_MODEL_0028f33795f0421c97192da5da8203e1","value":" 0/1 [00:00&lt;?, ?ba/s]"}},"8323f1abe1ef430da6d5586e77b19c5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b90c4c5a0da742b09f5010b882050d81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2d68edb9e6f43899fe859576ad727ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ea122e0b377435e95908562491c6032":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fae1579b95a4f7fb253596a8659e831":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c7e3daca9b3426d808eb566e1abb8fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0028f33795f0421c97192da5da8203e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# T5 for Text summarization (Pytorch)\n","\n","Text summarization is one of the most important NLP applications. This is a very difficult tasks that poses several challenges such as identifying the important content and generate a summary.\n","\n","In this notebook, we will fine-tune the pre-trained T5 for the task of text summarization. T5 has a encoder-decoder architecture. We will use the XSum dataset from Hugging Face Datasets.\n","\n","Unlike the previous notebook where we fine-tune a T5 model for this task on tensorflow, **the framework used will be Pytorch** in this notebook.\n","\n","Source: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb#scrollTo=imY1oC3SIrJf\n"],"metadata":{"id":"97ZiGntwTQLF"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"NcXBQ6WqTKxs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668087208727,"user_tz":-60,"elapsed":3271,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"6fb49410-4d4b-4fd6-8b7f-8b5f047d5ab1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n","Requirement already satisfied: keras_nlp in /usr/local/lib/python3.7/dist-packages (0.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.7)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.3.0)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (2.9.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (2.9.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.2.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.9.1)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.9.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.17.3)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (14.0.6)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.27.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.50.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.14.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (57.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.1.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.12)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras_nlp) (0.38.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras_nlp) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.8.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (3.2.2)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->keras_nlp) (0.12.0)\n"]}],"source":["!pip install transformers datasets rouge-score keras_nlp"]},{"cell_type":"markdown","source":["To ignore warning, please run the following cell:"],"metadata":{"id":"2gY4H_S9FLHs"}},{"cell_type":"code","source":["import transformers\n","print(transformers.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KSAzg2GDV2-","executionInfo":{"status":"ok","timestamp":1668087211544,"user_tz":-60,"elapsed":2820,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"c26b6550-8f52-4352-ab9e-21c340a6d46a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["4.24.0\n"]}]},{"cell_type":"markdown","source":["If you want that warnings are not printed, please run this cell:"],"metadata":{"id":"PZr7hPCjidoj"}},{"cell_type":"code","source":["import os\n","os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n","# ignore warning about deprecation\n","o_deprecation_warning=True\n"],"metadata":{"id":"bdFWgjzaDgA2","executionInfo":{"status":"ok","timestamp":1668087211544,"user_tz":-60,"elapsed":3,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Data\n","we use the dataset xsum that consists of 226,711 news BBC articles accompanied with a one-sentence summary. The articles covers a wide variety of domains (e.g., News, Politics, Sports, Weather, Business, Technology, Science, Health, Family, Education, Entertainment and Arts). \n","\n","The official random split contains 204,045 (90%), 11,332 (5%) and 11,334 (5) documents in training, validation and test sets, respectively.\n","\n","As the dataset is very large, we will use a smaller sample to run this notebook during the class:"],"metadata":{"id":"vrZ-iZkDUYXG"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","REDUCE_DATA = True\n","\n","if REDUCE_DATA:\n","    # we only load a smaller sample of the dataset for training a summarizer during this class \n","    dataset = load_dataset(\"xsum\", split='train[:1%]').shuffle(seed=42)\n","    # As we only got a smaller sample from the traing split, we need to create the splits\n","    dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n","    SIZE_TEST= 10\n","    dataset[\"validation\"] = dataset[\"test\"].select(range(SIZE_TEST,dataset[\"test\"].num_rows))\n","    # we only get SIZE_TEST for test\n","    dataset[\"test\"] = dataset[\"test\"].select(range(SIZE_TEST))\n","else:\n","    # this loads the full dataset; in this case, we don't have to create the splits, because it already contains them. \n","    dataset = load_dataset(\"xsum\")\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sf7zOv9PULB0","executionInfo":{"status":"ok","timestamp":1668087213547,"user_tz":-60,"elapsed":2006,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"b1304e60-9aaa-4d03-a8a5-041ca39b1349"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n","WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934/cache-4e8935f7a3554cf3.arrow\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['document', 'summary', 'id'],\n","        num_rows: 1632\n","    })\n","    test: Dataset({\n","        features: ['document', 'summary', 'id'],\n","        num_rows: 10\n","    })\n","    validation: Dataset({\n","        features: ['document', 'summary', 'id'],\n","        num_rows: 398\n","    })\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["We show some instances. We should always obtain the same ids if we set the seed to 42"],"metadata":{"id":"W8kpIStI_diC"}},{"cell_type":"code","source":["print(dataset['train'][0]['id'])  #36884862     (if the dataset was reduced)\n","print(dataset['validation'][0]['id']) #27929646 (if the dataset was reduced)\n","print(dataset['test'][0]['id']) # 34493630 (if the dataset was reduced)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLBEIwbC_ejx","executionInfo":{"status":"ok","timestamp":1668087213547,"user_tz":-60,"elapsed":4,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"b0f5c9e5-5934-447c-f33c-d914531339a8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["36884862\n","36219003\n","34493630\n"]}]},{"cell_type":"markdown","source":["### Tokenization"],"metadata":{"id":"4ZID6Tv7VY51"}},{"cell_type":"code","source":["PREFIX='summarize: '\n","MAX_INPUT_LENGTH = 1043  #  Maximum length of the input to the model. Use 1024 when Transformers v5.\n","MAX_TARGET_LENGTH = 128  # Maximum length of the output by the model"],"metadata":{"id":"ESuGReB6V6BJ","executionInfo":{"status":"ok","timestamp":1668087213548,"user_tz":-60,"elapsed":3,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","model_name = 't5-small'\n","# we must instanciate the tokenizer using model_max_length to increase the maximu length of the model from 512 to \n","tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=MAX_INPUT_LENGTH)\n","# print(tokenizer.model_max_length)\n","\n","def tokenize(examples):\n","    \"\"\"For each example in the dataset examples, the function will tokenize the input document \n","    but also the expected output, that is, its summary. This will be saved into a new field of the dataset with \n","    the name 'labels'. We only need to save the input_ids of the summary.\"\"\"\n","    inputs = [PREFIX + doc for doc in examples[\"document\"]]\n","    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n","\n","    # Setup the tokenizer for targets\n","    # with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(text_target=examples[\"summary\"], max_length=MAX_TARGET_LENGTH,  padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n","\n","    # we add a new feature labels to contain the encoded output\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","    return model_inputs\n","\n","# we apply the function to the dataset for encoding it\n","encoded_datasets = dataset.map(tokenize, batched=True)\n","encoded_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363,"referenced_widgets":["c772978606ed46da89e25e569c20e29a","33ae62037c804e49b1b427a6c397b32f","e1a2fd7ef56d4470b6e917987e6c619c","b621da29cbe0463e830ddf1650a1f9f1","de54be6ca6b44d64a8f9591f7c8ec55b","19fc60106ea94f72b87ddbc71ddffcd9","7bbc9322a83f4be0a3b37cba54285f40","38e7132a92b14e7db00889124f91f952","984d7e02e522475fac50fc638f21aea4","8e1606e7fcf64bf58802a569731b23e2","44eaf1c99cf841ffb983517e9adc7592","9f02ae431af34e48aa82762df714ee5c","5891bfbe7e074d519f9836d9b803e448","2c2992cb15d14fc5a257aee743a4ff5b","0bbeb05101b8439ea6006e8e2471e239","dbd70e16f0b5411c9dfd120abad17d05","5ea873a529c6450ab60a71382d6c5176","1ca7597596f845508b3b9dd9e9e7f3d7","8b2533f732444a7e99827c3d46fd9948","e0b713f2173743bc99ca967bbcc2d2a5","ed1c3be4e48a4b02b858a4fe2c5759d0","83fc4ce02a354cceb24dee396f0e8514","664f24aae2d1482f8f4b7d48593078d0","4933b1910d014b378de0e9a303f6b372","16f0414888264f459c767fc08522d8e4","8da587deadd44c86b0bff900027bbc0d","8323f1abe1ef430da6d5586e77b19c5b","b90c4c5a0da742b09f5010b882050d81","a2d68edb9e6f43899fe859576ad727ab","1ea122e0b377435e95908562491c6032","6fae1579b95a4f7fb253596a8659e831","1c7e3daca9b3426d808eb566e1abb8fe","0028f33795f0421c97192da5da8203e1"]},"id":"Hm09FkNKVa_8","executionInfo":{"status":"ok","timestamp":1668087218373,"user_tz":-60,"elapsed":4828,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"8facdd39-1c98-44ed-99c7-9414a2fce598"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c772978606ed46da89e25e569c20e29a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f02ae431af34e48aa82762df714ee5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"664f24aae2d1482f8f4b7d48593078d0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1632\n","    })\n","    test: Dataset({\n","        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 10\n","    })\n","    validation: Dataset({\n","        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 398\n","    })\n","})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["encoded_datasets=encoded_datasets.remove_columns(['document', 'summary', 'id'])\n","encoded_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9JNBremrlRr","executionInfo":{"status":"ok","timestamp":1668087218374,"user_tz":-60,"elapsed":4,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"9af65f6d-1f0a-4100-9c9d-b3833e47359e"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1632\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 10\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 398\n","    })\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## Model (Pytorch)\n","\n","Here is when the code is different to the previous notebook where we fine-tune a T5 for text summarization on tensorflow. \n","Now we have to use differente classes:\n"],"metadata":{"id":"xxU7snRPYKCQ"}},{"cell_type":"markdown","source":["### Defining model, arguments and data collator"],"metadata":{"id":"PQcWmzjWwHEi"}},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to('cuda')\n"],"metadata":{"id":"khWlOkf0YLpC","executionInfo":{"status":"ok","timestamp":1668087219770,"user_tz":-60,"elapsed":1398,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["We will use a trainer class for Seq2Seq, so we need to set its arguments:"],"metadata":{"id":"EBGCjiGOl7Mj"}},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments\n","\n","batch_size = 16\n","args = Seq2SeqTrainingArguments(\n","    output_dir='./outputs',\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=1,\n","    predict_with_generate=True,\n","    fp16=True,\n",")"],"metadata":{"id":"3iaWX6KDl6k_","executionInfo":{"status":"ok","timestamp":1668087219770,"user_tz":-60,"elapsed":4,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["We also need to define a data collator, in particular, one for a Seq2Seq model:\n"],"metadata":{"id":"ZFEuZnQqkwDb"}},{"cell_type":"code","source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"3AG2VqRJmUn_","executionInfo":{"status":"ok","timestamp":1668087219770,"user_tz":-60,"elapsed":2,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Metrics for the trainer\n","We also have to define the function that will be used by the trainer to measure the model on the validation dataset:"],"metadata":{"id":"9A3CAd8fmkhs"}},{"cell_type":"code","source":["import keras_nlp\n","rouge_L = keras_nlp.metrics.RougeL()\n","\n","def compute_metrics(eval_predictions):\n","    #the predictions and the corresponding reference labels\n","    predictions, labels = eval_predictions\n","\n","    # we have to decode the predictions\n","    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    \n","    # we also have to decode the reference labels\n","    # first, we replace those labels <0 with the token id for padding\n","    for label in labels:\n","        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n","    # we now decode the reference labels\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    # we calculate rouge_L comparing the decoded labels and the decoded prediction\n","    result = rouge_L(decoded_labels, decoded_predictions)\n","    # We will print only the F1 score, you can use other aggregation metrics as well\n","    result = {\"RougeL\": result[\"f1_score\"]}\n","\n","    # return metric.compute(decoded_labels, decoded_predictions)\n","    return result"],"metadata":{"id":"1e3efjfIaP0N","executionInfo":{"status":"ok","timestamp":1668087220707,"user_tz":-60,"elapsed":939,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### Trainer \n","\n","Now, we can define the trainer object by using the *Seq2SeqTrainer* class:"],"metadata":{"id":"tFcyT58nFmKY"}},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=encoded_datasets[\"train\"],\n","    eval_dataset=encoded_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVxiIhVQaZzi","outputId":"a166841c-0146-4fe0-a4f1-5b1284056310","executionInfo":{"status":"ok","timestamp":1668087220708,"user_tz":-60,"elapsed":6,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cuda_amp half precision backend\n"]}]},{"cell_type":"markdown","source":["Finally, we train:"],"metadata":{"id":"l6pgK7wpnFSy"}},{"cell_type":"markdown","source":["### Evaluation on the validation dataset\n","We evaluate eth"],"metadata":{"id":"7ftp3lDIwbDE"}},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"id":"xuDdyG_hnIl5","executionInfo":{"status":"ok","timestamp":1668087265257,"user_tz":-60,"elapsed":44552,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"81a5eb54-9a26-42cb-91f2-d5d10dbaa5ea"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1632\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 102\n","  Number of trainable parameters = 60506624\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [102/102 00:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rougel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>3.625660</td>\n","      <td>tf.Tensor(0.107309885, shape=(), dtype=float32)</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 398\n","  Batch size = 16\n","Trainer is attempting to log a value of \"0.10730988532304764\" of type <class 'tensorflow.python.framework.ops.EagerTensor'> for key \"eval/RougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=102, training_loss=7.510858273973652, metrics={'train_runtime': 44.3155, 'train_samples_per_second': 36.827, 'train_steps_per_second': 2.302, 'total_flos': 449952277856256.0, 'train_loss': 7.510858273973652, 'epoch': 1.0})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"LNfo32h9r2Hz","executionInfo":{"status":"ok","timestamp":1668087277033,"user_tz":-60,"elapsed":11779,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"4fa3c786-195d-4d26-cf41-b8e7fd5bea57"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 398\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25/25 00:09]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"0.1073099821805954\" of type <class 'tensorflow.python.framework.ops.EagerTensor'> for key \"eval/RougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 3.6256604194641113,\n"," 'eval_RougeL': <tf.Tensor: shape=(), dtype=float32, numpy=0.10730998>,\n"," 'eval_runtime': 11.5393,\n"," 'eval_samples_per_second': 34.491,\n"," 'eval_steps_per_second': 2.167,\n"," 'epoch': 1.0}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":[],"metadata":{"id":"IZo8CJOpv-sF"}},{"cell_type":"markdown","source":["## Evaluation\n"],"metadata":{"id":"DpK5fZ4mv-xN"}},{"cell_type":"markdown","source":["### Inference\n","You can directly use the model to generate the summary for some text from the test dataset (or any another text). To do this, we create a pipeline object containing the model and the tokenizer."],"metadata":{"id":"Nat_ixkemV-c"}},{"cell_type":"code","source":["from transformers import pipeline\n","MIN_TARGET_LENGTH = 5\n","summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0)\n","\n","summarizer(\n","    dataset[\"test\"][0][\"document\"],\n","    min_length=5,\n","    max_length=120,\n","    # max_new_tokens=MAX_TARGET_LENGTH,\n",")"],"metadata":{"id":"k28BiRMfmXcN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668087277841,"user_tz":-60,"elapsed":810,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"cceb92db-0237-4767-e48f-b1681564aaaf"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'summary_text': \"Virgil van Dijk's first goal for 18 months gave the hosts the lead . he doubled the lead with a header from Dusan Tadic's corner . the 28-year-old is the fourth englishman to score in six consecutive matches this season .\"}]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["dataset[\"test\"][0][\"summary\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"d-H_uZD1xV-C","executionInfo":{"status":"ok","timestamp":1668087277841,"user_tz":-60,"elapsed":5,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"0090bf8f-b31c-4327-c221-d7fdfd5ce8ac"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Premier League top scorer Jamie Vardy scored twice as Leicester came from 2-0 down to draw at Southampton.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["dataset[\"test\"][0][\"document\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"jtLAaQBNsvoE","executionInfo":{"status":"ok","timestamp":1668087277842,"user_tz":-60,"elapsed":5,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"d60423f7-40aa-4554-c546-c445cebe8c4c"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Jose Fonte\\'s first goal for 18 months gave the hosts the lead, glancing in a header from Dusan Tadic\\'s corner.\\nVirgil van Dijk earlier saw a header cleared off the line, but he doubled the lead with a close-range prod.\\nVardy headed the Foxes back into the match, before blasting home his ninth of the season in injury time to keep the Foxes in fifth.\\nRelive the match action here\\nAll the Premier League action and reaction\\nNot judging by their second-half display.\\nThe Foxes have scored in every Premier League match this season and, sparked into life by the half-time introduction of forwards Riyad Mahrez and Nathan Dyer, they earned an unlikely point with a stunning final 45 minutes.\\nSouthampton were in complete control at half-time but, helped by the trickery of Mahrez and the clinical finishing of Vardy, the Foxes again showed they should never be ruled out.\\nThe draw is the seventh point Leicester have earned from a losing position this season.\\nIt would be very hard to leave the Leicester and England striker at home in the summer on this form.\\nThe 28-year-old, who was playing for Fleetwood in League Two in 2012, became just the fourth Englishman to score in six consecutive Premier League matches this century when he headed home to give the Foxes hope after the break.\\nBefore he hammered in a late equaliser, the striker shot over from close range and was a constant threat for Leicester after the break.\\nVardy, already in the England squad, is playing with a double fracture to his wrist, but looks determined to push his international cause with the likes of Liverpool\\'s Danny Ings and Daniel Sturridge struggling with injury.\\nHe now has three more goals than any of his Premier League rivals.\\nMedia playback is not supported on this device\\nThe introduction of Leicester substitutes Mahrez and Dyer at the start of the second half changed the pattern of the game.\\nAlgerian Mahrez has been a key player for the Foxes this season and the forward proved so again, creating chance after chance playing just behind striker Vardy.\\nIt was his pass that created the equaliser while Swansea City loanee Dyer also made a big impact on the wing, crossing for Vardy\\'s opener.\\nSouthampton should have had the game out of sight, with Sadio Mane delaying after rounding goalkeeper Kasper Schmeichel when 2-0 up, but the hosts tired as the match wore on with all 10 of their starting outfield players involved in international duty in the past week.\\nSouthampton boss Ronald Koeman on BBC Sport: \"It was a difficult game. Defensively we did well in the first half and we scored from set pieces.\\n\"But I expected a difficult second half because we know one of Leicester\\'s strengths is unbelievable spirit and we have to be more clever.\\nMedia playback is not supported on this device\\n\"They deserved at least one point. They did two good changes after half-time. Mahrez created difficulties for us.\"\\nLeicester boss Claudio Ranieri on BBC Sport: \"We have fantastic spirit. We believe everything could be possible.\\n\"We created a lot of chances. It is important to have good players on the bench and I have very good players who can change the match.\\n\"Jamie Vardy is very important for us. I believe in this team. When we are desperate we make more, more and more.\"\\nIt doesn\\'t get any easier for Southampton as they face a trip to Liverpool for Jurgen Klopp\\'s first home match in charge of the Reds. Leicester entertain Crystal Palace looking to maintain their top five spot.\\nMore follows.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["### Results on the test dataset\n","We also want to provide some final scores about our model on the test dataset"],"metadata":{"id":"VJx8gx_yvwLy"}},{"cell_type":"code","source":["generated_summaries =summarizer(dataset[\"test\"][\"document\"], truncation=True, min_length=MIN_TARGET_LENGTH, max_length=MAX_TARGET_LENGTH)\n","generated_summaries=[example['summary_text'] for example in generated_summaries]\n","\n","result = rouge_L(dataset[\"test\"][\"summary\"], generated_summaries)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkD0eO6aOUrR","outputId":"57762bc5-477b-4c8d-ed95-27e995527015","executionInfo":{"status":"ok","timestamp":1668087285244,"user_tz":-60,"elapsed":7407,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Disabling tokenizer parallelism, we're using DataLoader multithreading already\n","Your max_length is set to 128, but you input_length is only 91. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","#print(\"rouge-L:\", result['precision'], result['recall'], result['f1_score'])\n","print(\"rouge-L -  Precision:\", tf.get_static_value(result['precision']), \", Recal: \", tf.get_static_value(result['recall']), \", f1-score:\", tf.get_static_value(result['f1_score']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWa0D1xMtE5w","executionInfo":{"status":"ok","timestamp":1668087285244,"user_tz":-60,"elapsed":5,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"32b40dbb-15f6-49b3-88f8-257b56633369"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["rouge-L -  Precision: 0.14080042 , Recal:  0.090049334 , f1-score: 0.10729898\n"]}]}]}
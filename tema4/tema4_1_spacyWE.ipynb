{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/OCW-UC3M-NLPDeep-2023/blob/main/tema4_1_spacyWE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\" width=50%/>\n",
        "\n",
        "<h1><font color='#12007a'>Procesamiento de Lenguaje Natural con Aprendizaje Profundo</font></h1>\n",
        "<p>Autora: Isabel Segura Bedmar</p>\n",
        "\n",
        "<img align='right' src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>    "
      ],
      "metadata": {
        "id": "oE3pxgwxhVtr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGrlDTZC4rzv"
      },
      "source": [
        "# 4.1. Cómo utilizar los word embeddings de Spacy.\n",
        "\n",
        "Spacy proporciona diferentes modelos (https://spacy.io/usage/models) que permiten realizar tareas  de PLN como la tokenización, la lematización, el análisis de dependencias, etc.\n",
        "\n",
        "Algunos de estos modelos además incluyen vectores de palabras que pueden ser utilizados para medir la similitud entre palabras o entre textos.\n",
        "\n",
        "Los modelos que terminan en -sm (small) no incluyen vectores de palabras.\n",
        "\n",
        "\n",
        "El primer paso será instalar la librería spacy:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy"
      ],
      "metadata": {
        "id": "KBmzuPUvjNW1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, vamos a descargar y cargar uno de estos modelos. Por ejemplo, el modelo **es_core_news_md** para procesar textos en español (optimizado para CPU). Este modelo incluye los siguientes componentes: tok2vec, morphologizer, parser, senter, ner, attribute_ruler, lemmatizer. Además, incluye un modelo de vectores con unos 20.000 vectores. Los vectores tienen dimensión 300."
      ],
      "metadata": {
        "id": "Io6qmtJTiwWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download es_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4PfwtnjjXR",
        "outputId": "8beec37d-37f7-4ecf-f76b-b12795b2dc52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-27 07:56:13.663267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-27 07:56:16.610048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting es-core-news-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.6.0/es_core_news_md-3.6.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-md==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"es_core_news_md\")\n"
      ],
      "metadata": {
        "id": "SurhMRy6i_44"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnRCjngTmwsH"
      },
      "source": [
        "Ahora vamos a utilizar dicho modelo para procesar algunas palabras y estudiar sus embeddings. Es decir, vamos a aplicar el objeto nlp, creado en la celda anterior, para procesar una secuencia de palabras. De cada palabra, vamos a consultar los siguientes atributos:\n",
        "- **text**: el texto del token (palabra).\n",
        "- **has_vector**: atributo booleano que nos indica si el token tiene un vector o no.\n",
        "- vector_norm: nos devuelve la norma del vector (la raíz cuadrada de la suma de los cuadrados de sus elementos).\n",
        "- is_oov: es True si la palabra forma parte del vocabulario y False en otro caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN1HwyN6lsP1",
        "outputId": "5f1580be-b1ca-44cf-d430-2e65ce693dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = nlp(\"caballo yegua potro vaca manzana naranja iansdiufnas Falcado\")\n",
        "\n",
        "for token in tokens:\n",
        "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caballo True 22.985107 False\n",
            "yegua True 26.477182 False\n",
            "potro True 22.985107 False\n",
            "vaca True 30.985302 False\n",
            "manzana True 19.44172 False\n",
            "naranja True 18.938 False\n",
            "iansdiufnas False 0.0 True\n",
            "Falcado False 0.0 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las únicas palabras que no tienes vector asociado son: **iansdiufnas**, que claramente no existe, y **falcado**, una palabra poco común en español y cuyo significado es curvado con forma de hoz.\n",
        "\n",
        "\n",
        "Para poder acceder al embedding, directamente debemos invocar el atributo **vector**:"
      ],
      "metadata": {
        "id": "i8_YTACzkqJ5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11jCzhqZshRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0b7122-fd68-464c-b591-58b5ce9a4eff"
      },
      "source": [
        "token1=tokens[0]\n",
        "print(\"dimensión: \", len(token1.vector))\n",
        "print(token1.text, \":\", token1.vector)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimensión:  300\n",
            "caballo : [ 1.6796e+00  6.9239e-01 -1.0369e+00  2.2072e+00  1.1877e+00 -1.2560e+00\n",
            "  1.6072e-01  1.2165e+00 -8.3058e-02  2.9497e-01 -1.8744e+00  8.9574e-01\n",
            " -2.7154e-01 -5.5810e-01 -1.1556e+00 -2.8373e+00 -2.6771e+00 -7.0166e-02\n",
            "  5.4694e-02  9.0240e-01 -1.5919e-01 -7.6455e-02  3.2906e-01  8.3176e-01\n",
            "  6.7742e-01 -1.6503e+00  6.5548e-01 -5.0972e-01  7.3731e-01  1.9637e+00\n",
            " -1.8252e+00  1.0735e-01  1.5032e+00  5.8705e-01 -2.8360e+00 -1.0602e+00\n",
            "  8.6917e-01 -4.9286e-01  1.6447e+00 -1.2131e+00 -2.0851e-01  1.1079e+00\n",
            " -2.8351e-01  3.9133e+00 -2.1549e+00 -9.1772e-01  1.3531e+00 -1.9251e+00\n",
            " -8.3949e-01 -1.4306e+00  4.5392e-01  9.9385e-01  9.6361e-01 -4.0914e-01\n",
            " -2.4818e+00 -1.2071e+00 -5.1422e-01 -8.5908e-01  1.8626e+00  2.9035e+00\n",
            "  1.8261e-01  1.7438e+00  2.3146e+00 -7.7685e-01  1.9547e+00 -7.9520e-02\n",
            "  4.3168e-01 -6.7273e-01 -2.4355e+00 -4.1766e-02 -4.3220e-01 -7.5098e-01\n",
            "  2.3693e-01  1.2240e+00  1.9430e+00  1.2342e+00  7.1813e-01  2.5070e+00\n",
            " -2.2650e+00 -2.3766e+00 -1.0169e+00 -2.0061e+00 -3.8741e-01 -3.6915e-01\n",
            " -2.0060e+00  1.4501e+00 -2.6306e-01  6.3394e-01  2.8265e-01 -7.9966e-01\n",
            "  1.0390e+00 -2.3245e+00 -1.4201e+00 -1.6005e+00  2.7751e+00  9.5170e-01\n",
            " -2.9779e-01 -6.2641e-01  8.9069e-02  1.4007e+00 -3.5787e-01  8.4182e-01\n",
            " -5.7979e-01  3.8239e-01  4.1872e-01  6.2798e-01 -1.3320e+00  1.5864e-01\n",
            " -3.8694e-01 -2.8425e-01 -1.2391e+00 -1.5491e+00  1.0931e+00 -2.7785e-01\n",
            "  1.9578e-01  2.8944e-01 -3.2387e+00  1.1081e+00 -1.3863e+00 -3.4909e-01\n",
            "  1.1596e-01  1.7240e+00 -2.4034e+00 -1.0727e-01  4.1918e-03 -1.6622e-01\n",
            " -1.7584e+00 -5.1316e-01  1.8395e+00 -9.2453e-01  4.0803e-01  5.3360e-01\n",
            "  1.1190e+00 -8.9896e-01  4.1173e-01  1.0552e+00 -2.7259e+00  1.6686e+00\n",
            " -2.5611e-01  2.7619e-01  5.8456e-01 -2.6349e+00  6.5262e-01  6.6642e-02\n",
            "  6.3529e-01  1.6039e+00 -1.2253e+00  3.4975e-01 -6.1071e-01  9.2512e-01\n",
            "  4.0902e-01 -3.1138e-01 -1.2346e+00  1.0180e+00  1.3439e+00  2.1544e+00\n",
            "  6.9470e-01  6.7084e-02  1.9274e+00 -2.3827e+00  2.5092e-03  1.2981e+00\n",
            "  3.9273e+00  1.3202e+00 -2.0500e+00  9.9907e-01 -8.9507e-01 -1.9068e+00\n",
            "  1.1145e+00 -6.3774e-01  1.1672e+00  1.6254e+00 -2.2032e+00  1.6160e+00\n",
            " -5.6705e-01 -3.2198e-01  4.9785e-01  3.5069e+00 -2.7079e-01  2.2594e+00\n",
            "  2.2050e+00 -1.0616e+00 -8.1441e-01 -7.5348e-02  2.5457e-01  7.7050e-02\n",
            " -1.6098e+00  1.9492e+00  5.9292e-01 -9.9064e-01  4.6607e-01  7.6451e-01\n",
            "  1.3092e+00  1.1494e+00  9.3296e-01 -1.8731e+00 -2.2407e-01  1.9903e-02\n",
            "  5.2403e-01 -2.3153e+00 -1.2810e+00 -1.2817e+00 -9.9854e-03  3.8240e-01\n",
            " -1.9355e+00  6.2427e-01  3.3367e-01 -1.9469e+00  2.7082e-01  7.9203e-01\n",
            " -2.1047e+00  6.4005e-01  1.2296e+00 -5.1115e-01 -1.0249e+00  2.9535e+00\n",
            "  1.2951e+00  8.7468e-01  1.7575e+00 -2.5918e+00 -1.0001e+00 -8.5573e-01\n",
            "  9.3439e-01 -3.2049e-01  1.6544e+00  2.9487e+00 -3.6225e-01 -4.5117e-02\n",
            " -4.1911e-03  3.0008e+00 -9.8967e-02 -8.3710e-01  9.7046e-01  4.0060e-02\n",
            " -5.4237e-01  6.0717e-01 -3.4935e-01  3.2127e-01  1.0196e+00 -9.3748e-01\n",
            " -1.0369e+00 -4.6080e-01 -4.2707e-01  1.3777e-01 -2.9705e-02  2.6617e+00\n",
            "  5.2205e-01 -9.6045e-01  8.2985e-02  1.3042e+00 -1.1879e+00 -2.2552e-01\n",
            " -6.9377e-01 -9.0488e-01  2.9200e-01 -1.5742e+00 -2.3062e-02 -2.1840e+00\n",
            "  1.3975e-01  8.7103e-02 -9.3909e-01 -5.1642e-01  1.6047e+00 -2.3537e-01\n",
            " -4.9534e-01  2.1810e+00  1.5099e+00 -2.2723e-01 -8.9794e-01 -1.8906e-01\n",
            " -1.0149e+00 -5.8296e-02 -9.3911e-01 -7.1397e-01 -9.7291e-01 -6.4243e-01\n",
            " -2.4605e-01  1.6943e+00  1.5029e+00 -2.9268e+00  8.3513e-01  3.0145e-01\n",
            "  3.0207e-01  8.3180e-01 -4.4635e-01  1.6708e+00  1.1207e+00 -1.2558e+00\n",
            "  1.3894e+00  6.2729e-01  2.0081e+00 -3.1380e+00  5.2460e-01  1.9021e+00\n",
            "  1.5138e+00 -2.0056e+00 -2.9416e-01 -4.8377e-01 -1.0776e+00  1.0394e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywqcIKk3mco5"
      },
      "source": [
        "Spacy nos proporciona un método para calcular la **similitud** (similarity) entre dos tokens (también puede ser utilizado para calcular la similitud entre dos textos). El método está basado en la **distancia del coseno**.\n",
        "\n",
        "El método devuelve un valor entre 0 y 1, donde un valor próximo a 1 significa que ambas tokens (o textos) tienen un significado muy similar similar, mientras un valor próximo a 0 indica que ambos tokens (o textos) no guardan similitud.\n",
        "\n",
        "En la siguiente celda, vamos a calcular la similitud de la primera palabra (**caballo**) con el resto de palabras. ¿Cuál es la palabra con mayor similitud?."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VYVucCXEWsb",
        "outputId": "8dada3af-5251-4165-c008-312f4564af1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "token1=tokens[0]\n",
        "for token in tokens[1:]:\n",
        "    print(token1,token,token1.similarity(token))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caballo yegua 0.3896075189113617\n",
            "caballo potro 0.9999998807907104\n",
            "caballo vaca 0.4315049350261688\n",
            "caballo manzana 0.19715562462806702\n",
            "caballo naranja 0.19350798428058624\n",
            "caballo iansdiufnas 0.0\n",
            "caballo Falcado 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-13b710075a3d>:3: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  print(token1,token,token1.similarity(token))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hP9d7zn_PO"
      },
      "source": [
        "También podemos comparar dos textos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6b9N0IgtXM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a099e06c-4027-438d-d779-63a89344ad27"
      },
      "source": [
        "doc1 = nlp(\"¿Cómo puedo desinstalar la aplicación?\")\n",
        "doc2 = nlp(\"¿Cómo puedo encontrar el verdadero amor?\")\n",
        "doc1.similarity(doc2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7478227116063041"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4ETYcotorj"
      },
      "source": [
        "En el anterior ejemplo, la similitud tiene un valor de 0.74, sin embargo, el significado de las palabras es completamente diferente.  \n",
        "Probablemente esa alta similitud se ha obtenido porque ambas oracioens comparten el mismo inicio (**¿Cómo puedo**). Si eliminamos ese comienzo, la similitud baja.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px7Mstw1uCq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90508317-84d1-4d93-f6a2-8dbeebcb9787"
      },
      "source": [
        "doc1 = nlp(\"desinstalar la aplicación?\")\n",
        "doc2 = nlp(\"encontrar el verdadero amor?\")\n",
        "doc1.similarity(doc2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31684383552078227"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"desinstalar la aplicación?\")\n",
        "doc2 = nlp(\"eliminar el software?\")\n",
        "doc1.similarity(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkBamWDfo7A4",
        "outputId": "f9d87f92-3214-4462-9ec1-d8acb6e397ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4280196172067276"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy incluye diferentes modelos con vectores de palabras. Estos vectores de palabras nos proporcionan un método sencillo para representar los textos, sino que además pueden ser utilizados directamente para calcular la similitud entre ellos."
      ],
      "metadata": {
        "id": "Jjh3xoXzpIzw"
      }
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f13a02485664f4aa93d99ac2cda25fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_633912a82b484a769d9e7600c4f8c955",
              "IPY_MODEL_11bd99e3b33e44488b37766d229a4902",
              "IPY_MODEL_18e441d343034b9280a7b7b9b749cda3"
            ],
            "layout": "IPY_MODEL_3b3b9e10ab214134abcf2fe2c50760ca"
          }
        },
        "633912a82b484a769d9e7600c4f8c955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db087092803433baa2fe9433bb12b3e",
            "placeholder": "​",
            "style": "IPY_MODEL_58723e5dd5a84204b64ada0e3deee5f5",
            "value": "Map: 100%"
          }
        },
        "11bd99e3b33e44488b37766d229a4902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec885c62dad476095803210693e7501",
            "max": 1632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a7c26836059421f8684e3df39640fa9",
            "value": 1632
          }
        },
        "18e441d343034b9280a7b7b9b749cda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f7f14107e84cdd8a6454eef9f08606",
            "placeholder": "​",
            "style": "IPY_MODEL_07647bf9c45941fb838bc870403982df",
            "value": " 1632/1632 [00:10&lt;00:00, 161.91 examples/s]"
          }
        },
        "3b3b9e10ab214134abcf2fe2c50760ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db087092803433baa2fe9433bb12b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58723e5dd5a84204b64ada0e3deee5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec885c62dad476095803210693e7501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a7c26836059421f8684e3df39640fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26f7f14107e84cdd8a6454eef9f08606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07647bf9c45941fb838bc870403982df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5534d4168b4f45b39517e26ec58f2bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7e6c08d5acf4b69a54f909d38a9f2a6",
              "IPY_MODEL_30df85ad48f14e4a9b2357827285721b",
              "IPY_MODEL_d46dd49b37ce4dc0a03387fbc75691a7"
            ],
            "layout": "IPY_MODEL_690d9e49fb1b4d1084ec13f9b66aa9ec"
          }
        },
        "d7e6c08d5acf4b69a54f909d38a9f2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27cf2bc85dbc41ec8d14f5ecd0ab2740",
            "placeholder": "​",
            "style": "IPY_MODEL_b8bddd4b4f794be390b66878f7dfca5f",
            "value": "Map: 100%"
          }
        },
        "30df85ad48f14e4a9b2357827285721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ead70e8d3c694590a411bb25da490cc0",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624ee41912ce427f85188d0b93230a3a",
            "value": 10
          }
        },
        "d46dd49b37ce4dc0a03387fbc75691a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec553fb586d41ba9a985f484e05f876",
            "placeholder": "​",
            "style": "IPY_MODEL_f86a0824d26743768b18da0ed8117091",
            "value": " 10/10 [00:00&lt;00:00, 118.37 examples/s]"
          }
        },
        "690d9e49fb1b4d1084ec13f9b66aa9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27cf2bc85dbc41ec8d14f5ecd0ab2740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8bddd4b4f794be390b66878f7dfca5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ead70e8d3c694590a411bb25da490cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624ee41912ce427f85188d0b93230a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bec553fb586d41ba9a985f484e05f876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86a0824d26743768b18da0ed8117091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c0ee65082d54a87b176dfe5bd4fa94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91ef80a5e64b4df582b8138dfb27b5f9",
              "IPY_MODEL_44ccb29673d543d4a38551c4767bf805",
              "IPY_MODEL_a42e8d1a20794419a724a84891bbe36d"
            ],
            "layout": "IPY_MODEL_df3c53c886c8400aaa894bda423750fb"
          }
        },
        "91ef80a5e64b4df582b8138dfb27b5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1d0c277d0645f796c4a015b3aa27c9",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7ecca630514900bbadb21c4b0d7780",
            "value": "Map: 100%"
          }
        },
        "44ccb29673d543d4a38551c4767bf805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f78e4cbc6694bc8ad533945725d5676",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e35c25053914d4a8ccf7261965e6618",
            "value": 398
          }
        },
        "a42e8d1a20794419a724a84891bbe36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b608cb526ebf48aebde2e689b8737c50",
            "placeholder": "​",
            "style": "IPY_MODEL_90222e7798ef4ea99e9ae5acc1ef924b",
            "value": " 398/398 [00:02&lt;00:00, 193.70 examples/s]"
          }
        },
        "df3c53c886c8400aaa894bda423750fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1d0c277d0645f796c4a015b3aa27c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7ecca630514900bbadb21c4b0d7780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f78e4cbc6694bc8ad533945725d5676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e35c25053914d4a8ccf7261965e6618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b608cb526ebf48aebde2e689b8737c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90222e7798ef4ea99e9ae5acc1ef924b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\" width=50%/>\n",
        "\n",
        "<h1><font color='#12007a'>Procesamiento de Lenguaje Natural con Aprendizaje Profundo</font></h1>\n",
        "<p>Autora: Isabel Segura Bedmar</p>\n",
        "\n",
        "<img align='right' src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>    "
      ],
      "metadata": {
        "id": "RSewR4cQ8kA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.5_ T5 para generación de resúmenes\n",
        "\n",
        "La generación de resúmenes es una las aplicaciones de PLN más importantes. Es una tarea muy difícil que plantea varios desafíos, como identificar el contenido importante y sintetizarlo todo en un nuevo texto.\n",
        "\n",
        "En este ejercicio, ajustaremos el transformer T5 a la tarea de generación de resúmenes. Este modelo tiene una arquitectura codificador-decodificador. Aunque puede ser utilizado para cualquier rtarea de NLP, es una buena opción en tareas de generación de textos, como la generaciónd e resúmenes.\n",
        "\n",
        "El dataset que vamos a utilizar es XSum (https://huggingface.co/datasets/xsum) un dataset formado por 226.711 noticias de la BBC y sus correspondientes resúmenes (cada resumen es una oración). Los artículos cubren una amplia variedad de dominios (por ejemplo, noticias, política, deportes, clima, negocios, tecnología, ciencia, salud, familia, educación, entretenimiento y artes).\n",
        "\n"
      ],
      "metadata": {
        "id": "97ZiGntwTQLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar librerías\n",
        "\n",
        "Además de instalar las librerías de transformers y datastes, también instalaremos la librería keras_nlp, que será utilizada para calcular la métrica rouge_L para la tarea de generación de resúmenes:"
      ],
      "metadata": {
        "id": "kw25BQmRwrlu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NcXBQ6WqTKxs"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers[torch] datasets rouge-score keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar el dataset\n",
        "\n",
        "Vamos a cargar el dataset XSum desde Hugging Face. Puede tardar unos minutos....\n"
      ],
      "metadata": {
        "id": "vrZ-iZkDUYXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"xsum\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OnlS-F-xipv",
        "outputId": "20acaea5-2192-401b-aeb6-db2edb590eac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 204045\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 11332\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 11334\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el split train contiene aproximadamente un 90% del dataset original (204.045 noticias), mientras que los conjuntos de validación y test tienen únicamente un 5% cada uno de ellos.\n",
        "\n",
        "Aunque disponer de datasets de gran tamaño siempre es una ventaja, para este ejercicio, únicamente usaremos una pequeña porción del dataset, para que el modelo pueda ser entrenado en Google Colab (sin usar el servicio Pro) y en un tiempo razonable.\n",
        "\n",
        "En concreto, lo que vamos a hacer es tomar un 1% del training (que serán unas 2000 instancias). De la muestra obtenida, reservaremos un 80% para el split de train (unas 1600 instancias) y el resto para validación y test. Este último con solo 10 instancias.\n",
        "\n",
        "Vamos a liberar primero la memoria ocupada por todo el dataset:"
      ],
      "metadata": {
        "id": "rKZwXnJqxpOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(dataset)"
      ],
      "metadata": {
        "id": "ihVoeKO20mC0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora creamos el nuevo dataset tomando únicamente un 1% del training. De esta muestra, obtenemos también los conjuntos de validación y test."
      ],
      "metadata": {
        "id": "mDKjLU_KDd-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# únicamente tomamos un 1% del training\n",
        "dict_dataset = load_dataset(\"xsum\", split='train[:1%]').shuffle(seed=42)\n",
        "\n",
        "# De esa misma muestra, vamos a obtener otros dos subconjuntos\n",
        "dict_dataset = dict_dataset.train_test_split(test_size=0.2, shuffle=False)\n",
        "\n",
        "SIZE_TEST=  dict_dataset[\"test\"].num_rows\n",
        "# en el conjunto de validación, desde la instancia 10 hasta el final del test\n",
        "dict_dataset[\"validation\"] = dict_dataset[\"test\"].select(range(10,SIZE_TEST))\n",
        "\n",
        "# en el conjunto test, únicamente guardamos las 10 primeras\n",
        "dict_dataset[\"test\"] = dict_dataset[\"test\"].select(range(10))\n",
        "\n",
        "dict_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf7zOv9PULB0",
        "outputId": "999b27f2-368c-40de-fa08-2399c8e71e5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 1632\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 398\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a mostrar algunas instancias"
      ],
      "metadata": {
        "id": "W8kpIStI_diC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "index = random.randint(0, dict_dataset['train'].num_rows)\n",
        "print('Texto original:\\n\\t',dict_dataset['train'][index]['document'])\n",
        "print()\n",
        "print('Resumen:\\n\\t', dict_dataset['train'][index]['summary'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLBEIwbC_ejx",
        "outputId": "ef2aee3d-7c54-49ac-ed81-6fb75e2ac996"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original:\n",
            "\t The closures from 20:00 to 06:00 BST from Monday should only affect traffic in one direction, although at times both tunnels may be closed.\n",
            "Newport's A48 Southern Distributor Road will be used for diversions.\n",
            "Economy and Infrastructure Secretary Ken Skates said there was an \"ongoing commitment\" to improving the motorway.\n",
            "The work is due to be carried out mainly at night until February 2018, with the M4 scheduled to be closed between junctions 25A for Caerleon and Cwmbran and 26 at Malpas up to five nights a week.\n",
            "Diversions will be put in place between junction 24 at Coldra and junction 28 at Tredegar Park for through traffic, although local traffic will be allowed to travel up to junctions 25A and 26 to access local routes.\n",
            "\"The M4 is of vital importance to the Welsh economy and this maintenance to the Brynglas tunnels forms part of our ongoing commitment to improving the motorway,\" said Mr Skates.\n",
            "\"The timing of this work is designed to ensure that it's carried out safely and as quickly as reasonably possible, with minimal possible disruption to road users.\"\n",
            "\n",
            "Resumen:\n",
            "\t Nightly closures of the Brynglas tunnels on the M4 motorway in south Wales are starting as over 18 months of maintenance work is carried out.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribución de los tamaños de los textos"
      ],
      "metadata": {
        "id": "_aoy8Cat0FQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = 't5-small'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "h2F7XsSu0L21"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_train_texts = [len(tokenizer(text).input_ids) for text in dict_dataset['train']['document']]\n",
        "\n",
        "import pandas as pd\n",
        "df=pd.Series(len_train_texts)\n",
        "df.describe(percentiles=[0.25, 0.50, 0.75, 0.85, 0.90, 0.95, 0.99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEAFz7MS0WZ9",
        "outputId": "316915b8-54d3-44e4-a802-b34bb7800b6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1632.000000\n",
              "mean      530.046569\n",
              "std       401.863190\n",
              "min        19.000000\n",
              "25%       262.000000\n",
              "50%       421.000000\n",
              "75%       695.500000\n",
              "85%       918.350000\n",
              "90%      1070.900000\n",
              "95%      1338.900000\n",
              "99%      1903.830000\n",
              "max      3013.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tamaño máximo en las noticias es de 3013 tokens, sin embargo vemos que el 99% de los textos tienen un tamaño menor o igual a 1903, y el 90% de los textos tienen menos de 1070 tokens.\n"
      ],
      "metadata": {
        "id": "J7-BMcPt12sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len_train_sums = [len(tokenizer(text).input_ids) for text in dict_dataset['train']['summary']]\n",
        "\n",
        "import pandas as pd\n",
        "df=pd.Series(len_train_sums)\n",
        "df.describe(percentiles=[0.25, 0.50, 0.75, 0.85, 0.90, 0.95, 0.99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6spIDXy1xfE",
        "outputId": "030ac63a-503c-4222-d5c0-69f1770f687b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1632.000000\n",
              "mean       30.498775\n",
              "std         8.080602\n",
              "min         3.000000\n",
              "25%        25.000000\n",
              "50%        30.000000\n",
              "75%        35.000000\n",
              "85%        38.000000\n",
              "90%        40.000000\n",
              "95%        44.000000\n",
              "99%        54.690000\n",
              "max       129.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tamaño máximo en los resúmenes es de 129 tokens, sin embargo vemos que el 99% de los resúmenes tienen un tamaño menor o igual a 54, y el 90% de los textos tienen menos de 40 tokens.\n"
      ],
      "metadata": {
        "id": "cdBGpRHO2HUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization\n",
        "\n",
        "Como mucho otros transformers, el modelo T5 necesita que todas sus entradas tengan el mismo tamaño, y el tamaño máximo que admite es 512 tokens.\n",
        "Los recursos informáticos aumentan cuadráticamente con respecto a la longitud de la secuencia de entrada. Por tanto, esto aumenta el tiempo de entrenamiento y el consumo de memoria.\n"
      ],
      "metadata": {
        "id": "4ZID6Tv7VY51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nUo0o8kN4046",
        "outputId": "714e6f58-1a1f-4b76-f176-810730c56cc9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.34.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_INPUT_LENGTH = 512  #  Tamaño máximo para la entrada del modelo (si la versión de transformeres es 5, puedes usar hasta 1024)\n",
        "MAX_TARGET_LENGTH = 129  # Tamaño máximo de la salida generada por el modelo"
      ],
      "metadata": {
        "id": "ESuGReB6V6BJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volvemos a crear el objeto tokenizador, pero ahora indicando la longitud maxima."
      ],
      "metadata": {
        "id": "iyTIITWf5E3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=MAX_INPUT_LENGTH)\n",
        "print(tokenizer.model_max_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm09FkNKVa_8",
        "outputId": "0b13528d-f71c-45ac-e856-abe257f35f98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También vamos a definir la función tokenize, que es ligeramente distinta a las usadas para el modelo BERT.\n",
        "\n",
        "Una de las características de T5 es que como BERT puede ser ajustado a distintas tareas de NLP, pero es necesario indicarle el nombre de la tarea que va a realizar. En nuestro caso, tendremos que añadir a cada entrada, el prefijo \"summarize: \".\n"
      ],
      "metadata": {
        "id": "uBcOYaBM5QbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PREFIX='summarize: '\n",
        "\n",
        "def tokenize(examples):\n",
        "\n",
        "    # añadimos el prefijo a cada texto de la entrada\n",
        "    inputs = [PREFIX + doc for doc in examples[\"document\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "    # también tenemos que tokenizar los resúmenes (que serán nuestras labels)\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=MAX_TARGET_LENGTH,  padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "    # añadimos a la codificación de las entrada, model_inputs, un nuevo campo 'labels' que contiene\n",
        "    # los input_ids de los tokens del resumen\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# we apply the function to the dataset for encoding it\n",
        "encoded_datasets = dict_dataset.map(tokenize, batched=True)\n",
        "encoded_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362,
          "referenced_widgets": [
            "7f13a02485664f4aa93d99ac2cda25fe",
            "633912a82b484a769d9e7600c4f8c955",
            "11bd99e3b33e44488b37766d229a4902",
            "18e441d343034b9280a7b7b9b749cda3",
            "3b3b9e10ab214134abcf2fe2c50760ca",
            "3db087092803433baa2fe9433bb12b3e",
            "58723e5dd5a84204b64ada0e3deee5f5",
            "3ec885c62dad476095803210693e7501",
            "0a7c26836059421f8684e3df39640fa9",
            "26f7f14107e84cdd8a6454eef9f08606",
            "07647bf9c45941fb838bc870403982df",
            "5534d4168b4f45b39517e26ec58f2bc2",
            "d7e6c08d5acf4b69a54f909d38a9f2a6",
            "30df85ad48f14e4a9b2357827285721b",
            "d46dd49b37ce4dc0a03387fbc75691a7",
            "690d9e49fb1b4d1084ec13f9b66aa9ec",
            "27cf2bc85dbc41ec8d14f5ecd0ab2740",
            "b8bddd4b4f794be390b66878f7dfca5f",
            "ead70e8d3c694590a411bb25da490cc0",
            "624ee41912ce427f85188d0b93230a3a",
            "bec553fb586d41ba9a985f484e05f876",
            "f86a0824d26743768b18da0ed8117091",
            "6c0ee65082d54a87b176dfe5bd4fa94a",
            "91ef80a5e64b4df582b8138dfb27b5f9",
            "44ccb29673d543d4a38551c4767bf805",
            "a42e8d1a20794419a724a84891bbe36d",
            "df3c53c886c8400aaa894bda423750fb",
            "fe1d0c277d0645f796c4a015b3aa27c9",
            "ca7ecca630514900bbadb21c4b0d7780",
            "0f78e4cbc6694bc8ad533945725d5676",
            "2e35c25053914d4a8ccf7261965e6618",
            "b608cb526ebf48aebde2e689b8737c50",
            "90222e7798ef4ea99e9ae5acc1ef924b"
          ]
        },
        "id": "wsaU5xQX5Put",
        "outputId": "79a67cbf-9fb3-4e40-ea75-a7053775ae59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1632 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f13a02485664f4aa93d99ac2cda25fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5534d4168b4f45b39517e26ec58f2bc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/398 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c0ee65082d54a87b176dfe5bd4fa94a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1632\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 398\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a borrar las columnas que no utilizará el transformer (document, summary, e id).\n",
        "\n",
        "El módelo únicamente trabajará con los input-ids de los textos de entrada, su capa de attention_mask (distingue entre padding y token normal), y las labels (que son los input_ids de los tokens del resumen)"
      ],
      "metadata": {
        "id": "AvK3gAz06PB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_datasets=encoded_datasets.remove_columns(['document', 'summary', 'id'])\n",
        "encoded_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9JNBremrlRr",
        "outputId": "db4d8a95-dc8a-46ee-b2b7-76e6b78e650a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1632\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 398\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo (Pytorch)\n",
        "\n",
        "Vamos a utilizar la clase **AutoModelForSeq2SeqLM** que nos permite cargar un modelo y extender su arquitectura **seq2seq**. Esta arquitectura, compuesta por un codificador y un decodificador, es apropiada para las tareas de generación de textos, ya que reciben una secuencia de entrada (un texto) y deben generar una secuencia de salida (un resumen, por ejemplo).\n"
      ],
      "metadata": {
        "id": "xxU7snRPYKCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to('cuda')\n"
      ],
      "metadata": {
        "id": "khWlOkf0YLpC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como siempre tenemos que definir los hiper-parámetros y las métricas. Respecto a los hiper-parámetros usaremos la clase **Seq2SeqTrainingArguments** que ya nos proporciona un conjunto de hiperparámetros apropiados para esta tarea. Vamos a modificar algunos de ellos, como por ejemplo, el tamaño del batch y el número de epochs:"
      ],
      "metadata": {
        "id": "EBGCjiGOl7Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./outputs',\n",
        "    evaluation_strategy = 'epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")"
      ],
      "metadata": {
        "id": "3iaWX6KDl6k_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respecto a las métricas, usaremos las propias para la tarea de generación de resúmenes, como Rouge, que están implementadas en la librería **keras_nlp**. En concreto, vamos a usar rougeL, que es la métrica más común para este tipo de sistemas, y da una una puntuación basada en la longitud de la subsecuencia común más larga presente en el texto de referencia (resumen) y el texto generado.\n"
      ],
      "metadata": {
        "id": "9A3CAd8fmkhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp\n",
        "rouge_L = keras_nlp.metrics.RougeL()\n",
        "\n",
        "def compute_metrics(eval_predictions):\n",
        "    #tomamos las salidas del modelo y sus respectivas labels (son input_ids)\n",
        "    predictions, labels = eval_predictions\n",
        "\n",
        "    # para poder aplicar rougeL, tenemos que pasarlas a texto, para eso usamos el método\n",
        "    # batch_decode, que decodificará todas las predicciones. Con el parámetro skip_special_tokens,\n",
        "    # ignoramos los tokens especiales\n",
        "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # También tenemos que decodificar los input_ids de las labels, es decir,\n",
        "    # si algún id es < 0, lo reemplazamos por el id del token pad.\n",
        "    for label in labels:\n",
        "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
        "\n",
        "    # ahora ya podemos pasar de ids a texto, también usando la misma función e ignorando los tokens especiales\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # ya tenemos las prediciones y las labels transformadas a texto, y ahora así, podemos\n",
        "    # calcular la métrica con la función rouge_L proporcionada por la librería keras_nlp\n",
        "    result = rouge_L(decoded_labels, decoded_predictions)\n",
        "    # rouge_L devuelve precisión, recall y F1, nosotros únicamente vamos a usar su f1\n",
        "    # creamos un diccionario con el nombre de la métrica, y el valor de rouge_L f1\n",
        "    result = {\"RougeL\": result[\"f1_score\"]}\n",
        "\n",
        "    # devolvemos el diccionario\n",
        "    return result"
      ],
      "metadata": {
        "id": "1e3efjfIaP0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47234f9a-d31e-4c20-d183-2242eb05f2d9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para pasarle los datos al modelo, necesitamos crear un data collator específico para la tarea. Para ello usaremos, la clase **DataCollatorForSeq2Seq** :"
      ],
      "metadata": {
        "id": "ZFEuZnQqkwDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "3AG2VqRJmUn_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora ya sí podemos crear el trainer, que en este caso será un objeto de la clase *Seq2SeqTrainer*. Como siempre tenemos que pasarle el modelo, los argumentos, la función que calcula las métricas, los datos de conjunto training y validación codificados, el tokenizador y el data collator para transferir los datos al modelo:"
      ],
      "metadata": {
        "id": "tFcyT58nFmKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_datasets[\"train\"],\n",
        "    eval_dataset=encoded_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "XVxiIhVQaZzi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos (tardará unos minutos):"
      ],
      "metadata": {
        "id": "l6pgK7wpnFSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "xuDdyG_hnIl5",
        "outputId": "76eb355e-dde9-471a-9b8a-20aa2151bfb8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [102/102 01:12, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rougel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.889640</td>\n",
              "      <td>tf.Tensor(0.11931312, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Trainer is attempting to log a value of \"0.11931312084197998\" of type <class 'tensorflow.python.framework.ops.EagerTensor'> for key \"eval/RougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=102, training_loss=7.711432363472733, metrics={'train_runtime': 73.0489, 'train_samples_per_second': 22.341, 'train_steps_per_second': 1.396, 'total_flos': 220877820002304.0, 'train_loss': 7.711432363472733, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a evaluar el modelo sobre el conjunto de validación:"
      ],
      "metadata": {
        "id": "7ftp3lDIwbDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "LNfo32h9r2Hz",
        "outputId": "8582a278-7192-4394-c2cd-5b4ac557dcb0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"0.11931321769952774\" of type <class 'tensorflow.python.framework.ops.EagerTensor'> for key \"eval/RougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.8896400928497314,\n",
              " 'eval_RougeL': <tf.Tensor: shape=(), dtype=float32, numpy=0.11931322>,\n",
              " 'eval_runtime': 19.3016,\n",
              " 'eval_samples_per_second': 20.62,\n",
              " 'eval_steps_per_second': 1.295,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo obtiene una rouge_L (f1) de 0.119 sobre el conjunto de validación. Una puntuación de ROUGE cercana a cero indica poca similitud entre los resúmenes generados y los resúmenes de referencia.\n",
        "\n",
        "Seguramente si utilizamos más datos para entrenar y también incrementamos el número de epochs, este valor aumentaría.\n",
        "\n"
      ],
      "metadata": {
        "id": "IZo8CJOpv-sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación sobre el conjunto test\n",
        "\n",
        "Nuestro conjunto test es muy pequeño, pero aun así también vamos a calcular la métrica rouge-L sobre dicho conjunto.\n",
        "\n",
        "Para aplicar el modelo sobre dicho conjunto, vamos a encapsularlo en un pipeline.\n",
        "Antes de evaluarlo, vamos a aplicarlo sobre uno de los textos en el test para ver qué resumen genera:\n"
      ],
      "metadata": {
        "id": "VJx8gx_yvwLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0)\n",
        "\n",
        "input_text = dict_dataset[\"test\"][0][\"document\"]\n",
        "print(\"Texto:\", input_text)\n",
        "summarizer(\n",
        "    input_text,\n",
        "    min_length=5,\n",
        "    max_length=120,\n",
        "    # max_new_tokens=MAX_TARGET_LENGTH,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmksyhPmASpD",
        "outputId": "ad84876e-abcd-4aa1-8730-db91c6f0512c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto: Jose Fonte's first goal for 18 months gave the hosts the lead, glancing in a header from Dusan Tadic's corner.\n",
            "Virgil van Dijk earlier saw a header cleared off the line, but he doubled the lead with a close-range prod.\n",
            "Vardy headed the Foxes back into the match, before blasting home his ninth of the season in injury time to keep the Foxes in fifth.\n",
            "Relive the match action here\n",
            "All the Premier League action and reaction\n",
            "Not judging by their second-half display.\n",
            "The Foxes have scored in every Premier League match this season and, sparked into life by the half-time introduction of forwards Riyad Mahrez and Nathan Dyer, they earned an unlikely point with a stunning final 45 minutes.\n",
            "Southampton were in complete control at half-time but, helped by the trickery of Mahrez and the clinical finishing of Vardy, the Foxes again showed they should never be ruled out.\n",
            "The draw is the seventh point Leicester have earned from a losing position this season.\n",
            "It would be very hard to leave the Leicester and England striker at home in the summer on this form.\n",
            "The 28-year-old, who was playing for Fleetwood in League Two in 2012, became just the fourth Englishman to score in six consecutive Premier League matches this century when he headed home to give the Foxes hope after the break.\n",
            "Before he hammered in a late equaliser, the striker shot over from close range and was a constant threat for Leicester after the break.\n",
            "Vardy, already in the England squad, is playing with a double fracture to his wrist, but looks determined to push his international cause with the likes of Liverpool's Danny Ings and Daniel Sturridge struggling with injury.\n",
            "He now has three more goals than any of his Premier League rivals.\n",
            "Media playback is not supported on this device\n",
            "The introduction of Leicester substitutes Mahrez and Dyer at the start of the second half changed the pattern of the game.\n",
            "Algerian Mahrez has been a key player for the Foxes this season and the forward proved so again, creating chance after chance playing just behind striker Vardy.\n",
            "It was his pass that created the equaliser while Swansea City loanee Dyer also made a big impact on the wing, crossing for Vardy's opener.\n",
            "Southampton should have had the game out of sight, with Sadio Mane delaying after rounding goalkeeper Kasper Schmeichel when 2-0 up, but the hosts tired as the match wore on with all 10 of their starting outfield players involved in international duty in the past week.\n",
            "Southampton boss Ronald Koeman on BBC Sport: \"It was a difficult game. Defensively we did well in the first half and we scored from set pieces.\n",
            "\"But I expected a difficult second half because we know one of Leicester's strengths is unbelievable spirit and we have to be more clever.\n",
            "Media playback is not supported on this device\n",
            "\"They deserved at least one point. They did two good changes after half-time. Mahrez created difficulties for us.\"\n",
            "Leicester boss Claudio Ranieri on BBC Sport: \"We have fantastic spirit. We believe everything could be possible.\n",
            "\"We created a lot of chances. It is important to have good players on the bench and I have very good players who can change the match.\n",
            "\"Jamie Vardy is very important for us. I believe in this team. When we are desperate we make more, more and more.\"\n",
            "It doesn't get any easier for Southampton as they face a trip to Liverpool for Jurgen Klopp's first home match in charge of the Reds. Leicester entertain Crystal Palace looking to maintain their top five spot.\n",
            "More follows.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \"Virgil van Dijk's first goal for 18 months gave the hosts the lead . he doubled the lead with a header from Dusan Tadic's corner . the 28-year-old is the fourth englishman to score in six consecutive matches this season .\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué te parece el resumen?.\n",
        "\n",
        "Ahora sí vamos calcular las métricas sobre el conjunto test. Para ello aplicamos el pipeline sobre todo el conjunto test. Tardará un par de minutos (y eso que son solo 10 textos!!):"
      ],
      "metadata": {
        "id": "mVhT9uEgAyIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summaries =summarizer(dict_dataset[\"test\"][\"document\"], truncation=True, min_length=5, max_length=MAX_TARGET_LENGTH)\n",
        "generated_summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkD0eO6aOUrR",
        "outputId": "036ddb42-5dce-4cdb-ba8d-d038ccde57ac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 129, but your input_length is only 91. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \"Virgil van Dijk doubled the lead with a header from Dusan Tadic's corner . he scored his ninth of the season in injury time to keep the Foxes in fifth . the hosts have scored in every premier league match this season .\"},\n",
              " {'summary_text': 'images of a million or more Belgians trudging along the roads to the Netherlands or France have been strikingly similar each time . in 1914, cinema audiences across Britain, many of whom had probably thought this kind of thing would never happen in Europe again, watched jerky black and white newsreel pictures .'},\n",
              " {'summary_text': 'Hurtado joined the Royals from Pacos de Ferreira last summer . the 26-year-old has made 25 appearances for Peru, scoring two goals .'},\n",
              " {'summary_text': 'the prime minister received nearly $700m (£455m) in his bank account from a generous donor or donors . one Muslim official suggested that their party needed the funds to counter the \"Jewish threat\" in the last general election, while another said the donation was a gift for Malaysia\\'s efforts in fighting terrorism .'},\n",
              " {'summary_text': \"Radford's side came from behind to win a late 12-10 win at Old Trafford . despite the leaders looking set to be overturned by second-placed Warrington, Hull still have to host both Warrington and Wigan . the team have already qualified for the play-off semi-finals .\"},\n",
              " {'summary_text': 'acoustic experiments could not be carried out at Stonehenge . the derelict state of the site meant only a \"few weak echoes\" and no noticeable reverberation could be studied .'},\n",
              " {'summary_text': '\"infiltrators\" tried to stir chaos, but among those held was a 10-year-old boy . protesters say he was with his father - and both were detained . \"they pulled Suhair by her hair and took her away,\" one demonstrator says .'},\n",
              " {'summary_text': \"the Dickie Bird Foundation gives grants to under-privileged children . the 78-year-old was regarded as one of the game's most popular umpires . he retired in 1998 and set up a guard of honour .\"},\n",
              " {'summary_text': 'Molly-Mae Wotherspoon, aged six months, was attacked by a pit bull in October at her home in daventry . the baby died as a result of blood loss from head wounds inflicted by an american pit bull .'},\n",
              " {'summary_text': 'a state department spokesman says the election process is flawed . he says the government has side-lined opposition candidates . his closest rival, centre-right candidate Maximino Rodriguez, only received 14.2% of the vote .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summaries=[example['summary_text'] for example in generated_summaries]\n"
      ],
      "metadata": {
        "id": "YP7kcbfkBEXy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que ya tenemos los resúmenes generados, podemos compararlos con los resúmenes de referencia y calcular rouge_L:"
      ],
      "metadata": {
        "id": "yZVxTdgLBRHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = rouge_L(dict_dataset[\"test\"][\"summary\"], generated_summaries)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9iAM8xvBCeg",
        "outputId": "dec75c2f-792d-436d-d6d1-82f4d1d8057d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.15695055>,\n",
              " 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.09936103>,\n",
              " 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.119162194>}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como comentabamos antes rouge_L, además de F1, también prorporciona la precisión y recall. Los tres valoes son muy bajos lo que indica es que hay muy poca similitud entre los resúmenes generados y los resúmenes de referencia (como ocurría en el conjunto validación).\n",
        "\n",
        "Para tomar el valor de cada tensor, puedes usar el siguiente código:"
      ],
      "metadata": {
        "id": "KrQmMccIBc3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print('Precision (rouge_L):', tf.get_static_value(result['precision']))\n",
        "print('recall (rouge_L):', tf.get_static_value(result['recall']))\n",
        "print('f1_score (rouge_L):', tf.get_static_value(result['f1_score']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWa0D1xMtE5w",
        "outputId": "f13940e9-54cc-41e2-990e-6f93f707e9d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (rouge_L): 0.15695055\n",
            "recall (rouge_L): 0.09936103\n",
            "f1_score (rouge_L): 0.119162194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados que hemos obtenido son muy pobres. Esto se debe principalmente a que hemos utilizado un conjunto para entrenar demasiado pequeño (únicamente 1600 pares de textos). Esto lo hemos hecho para que el modelo pueda entrenarse en poco tiempo y sin necesidad de usar el servicio Google Colab Pro.\n",
        "Si estás interesado en la tarea de generación de resúmenes, te recomiendo que trates de utilizar todo el dataset o bien una muestra mayor al 1% (que es el tamaño que hemos usado en este ejercicio).\n",
        "\n",
        "Además, también te recomiendo que experimentes con el conjunto de hiperparámetros y en particular, que aumentes el número de epochs. Probablemente los resultados aumenten significativamente (aunque también lo hará el tiempo de entrenamiento).\n"
      ],
      "metadata": {
        "id": "Eja0z9pzCfL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hay un nuevo modelo de T5, LongT5 (https://huggingface.co/docs/transformers/model_doc/longt5), que usa el mecanimso Transient Global (TGlobal), y que obtiene mejores resultados en la tarea de generación de resúmenes. Su principal ventaja es que permite manejar entradas de hasta\n",
        "16.384 tokens.\n"
      ],
      "metadata": {
        "id": "E_iT-Cdm4g1b"
      }
    }
  ]
}
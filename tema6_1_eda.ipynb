{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3bSJKrx2W2Zp",
        "lMvTU_2fi49f",
        "7MW3ZEk6jyzv"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6PgDz/2cZCJ4/lDigxZJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/OCW-UC3M-NLPDeep-2023/blob/main/tema6_1_eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/47/Acronimo_y_nombre_uc3m.png\" width=50%/>\n",
        "\n",
        "<h1><font color='#12007a'>Procesamiento de Lenguaje Natural con Aprendizaje Profundo</font></h1>\n",
        "<p>Autora: Isabel Segura Bedmar</p>\n",
        "\n",
        "<img align='right' src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" width=15%/>\n",
        "</center>    "
      ],
      "metadata": {
        "id": "DRXL8ApLqs5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Easy Data Augmentation (EDA): textaugment package\n",
        "\n",
        "En este ejercicio, vamos a practicar con las técnicas  de data augmentation propuestas en el artículo:\n",
        "Wei, J., & Zou, K. (2019). **Eda: Easy data augmentation techniques for boosting performance on text classification tasks**. EMNLP 2019. https://aclanthology.org/D19-1670.pdf\n",
        "\n",
        "<br>\n",
        "\n",
        "e implementadas en la librería de Python, TextAugment (https://github.com/dsfsi/textaugment). Esta librería proporciona cuatro operaciones muy sencillas para generar nuevos textos a partir de otros originales,  que permitan entrenar modelos más robustos para aplicaciones PLN y evitar el overfitting.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k-PR7ClDT-mL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "El primer paso es instalar la librería:"
      ],
      "metadata": {
        "id": "NCYwJmyVirE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q textaugment"
      ],
      "metadata": {
        "id": "SeAuFeCvldPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4931cf2-63f4-439f-f364-8b4e644c0db2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sustitución de sinónimos\n",
        "En esta operación se eligen aleatoriamente n palabras de la oración (que no sean palabras de parada). Cada una de estas palabras son reemplazadas con uno de sus sinónimos, también elegidos al azar.\n",
        "Por ejemplo, data la siguiente oración:\n",
        "\n",
        "- *'This article will focus on summarizing data augmentation techniques in NLP.'*\n",
        "\n",
        "podría ser transformada en la siguiente: can be trasnformed to\n",
        "\n",
        "- *'This **write-up** will focus on summarizing data augmentation **methods** in NLP.'*\n",
        "\n",
        "donde dos palabras, **article** y **tecniques** fueron seleccionadas aleatoriamente y son reemplazadas por sus sinónimos **write-up** y **methods**, respectivamente.\n",
        "\n",
        "Para obtener los sinónimos, la librería **textaugment** utiliza otras librerías como **nltk** para obtener las palabras vacías. Además, **nltk** utiliza **WordNet**, un diccionario de inglés, o **OMW**, una versión multilingüe de WordNet, para obtener sinónimos.\n",
        "\n",
        "Por tanto, vamos a necesitar también instalar esta librería y descargar esos paquetes:"
      ],
      "metadata": {
        "id": "3bSJKrx2W2Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjTjOy8pmE05",
        "outputId": "7bf2d80c-71b2-47d3-9beb-60c0ae8600ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a utilizar la librería **textaugment** para generar nuevas oraciones utilizando el método de **synonym_replacement**:"
      ],
      "metadata": {
        "id": "91pLmgcBmjLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textaugment import EDA\n",
        "t = EDA()\n",
        "\n",
        "texts = [\"John is going to town\",\n",
        "         \"Samantha took the bus.\",\n",
        "         \"There is no play with fire.\",\n",
        "         \"Stop talking and open your book.\",\n",
        "         \"All nations and English regions produce their own local news programmes and other current affairs and sport programmes.\",\n",
        "         \"This article will focus on summarizing data augmentation techniques in NLP.\"]\n",
        "\n",
        "for text in texts:\n",
        "    new_text = t.synonym_replacement(text)\n",
        "    print('original text: ', text)\n",
        "    print('new text: ', new_text)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SuylnuulOoG",
        "outputId": "92d4209b-63a4-4e41-a0dd-5c979a0f2b85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:  John is going to town\n",
            "new text:  John is going to ithiel town\n",
            "\n",
            "original text:  Samantha took the bus.\n",
            "new text:  Samantha direct the bus.\n",
            "\n",
            "original text:  There is no play with fire.\n",
            "new text:  There is no playact with fire.\n",
            "\n",
            "original text:  Stop talking and open your book.\n",
            "new text:  Stop talking and afford your book.\n",
            "\n",
            "original text:  All nations and English regions produce their own local news programmes and other current affairs and sport programmes.\n",
            "new text:  All nations and English regions produce their own local news programmes and other current amour and sport programmes.\n",
            "\n",
            "original text:  This article will focus on summarizing data augmentation techniques in NLP.\n",
            "new text:  This article will focus on summarizing data point augmentation techniques in NLP.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inserción aleatoria.\n",
        "\n",
        "La segunda operación selecciona una palabra (que no sea stopword) de forma aleatoria, e inserta un sinónimo de dicha palabra en una posición aleatoria en la oración. Este proceso se realiza n veces.\n",
        "\n",
        "Para el ejemplo anterior:\n",
        "- *'This article will focus on summarizing data augmentation techniques in NLP.'*\n",
        "\n",
        "esta operación toma dos palabras al azar (**artículo** y **técnicas**), obtiene sus sinónimos y los inserta en una posición aleatoria en la oración:\n",
        "\n",
        "- *This article will focus on **write-up** summarizing data augmentation techniques in NLP **methods**.**\n",
        "\n",
        "Date cuenta que las palabras originales no son reemplazadas.\n"
      ],
      "metadata": {
        "id": "lMvTU_2fi49f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intercambio aleatorio\n",
        "\n",
        "La tercera operación elige aleatoriamente dos palabras en la oración e intercambia sus posiciones. Este proceso se puede hacer n veces.\n",
        "\n",
        "Para el ejemplo anterior:\n",
        "- *This article will focus on summarizing data augmentation techniques in NLP.*\n",
        "\n",
        "Esta operación toma dos palabras aleatorias (artículo y técnicas) y las intercambia, generando la siguiente oración:\n",
        "\n",
        "- *This **techniques** will focus on summarizing data augmentation **article** in NLP.*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7MW3ZEk6jyzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Deletion\n",
        "La última operación elimina aleatoriamente una palabra de la oración. Esta operación se puede ejecutar varias veces. Por ejemplo, dada la oración\n",
        "\n",
        "- *This article will focus on summarizing data augmentation techniques in NLP.*\n",
        "\n",
        "El método selecciona n palabras (digamos dos), por ejemplo, **will** y **techniques**, y las elimina de la oración.\n",
        "\n",
        "- *This article focus on summarizing data augmentation in NLP.*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8GjsrnGWkYiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a probar las operaciones:"
      ],
      "metadata": {
        "id": "vyAmtersoic8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "         \"Samantha took the bus.\",\n",
        "         \"There is no play with fire.\",\n",
        "         \"Stop talking and open your book.\",\n",
        "         \"I want to be a computer engineer.\"]\n",
        "for text in texts:\n",
        "    new_text = t.synonym_replacement(text)\n",
        "    print('original text: ', text)\n",
        "    print('synonym replacement: ', new_text)\n",
        "\n",
        "    new_text = t.random_insertion(text)\n",
        "    print('random_insertion: ', new_text)\n",
        "\n",
        "    new_text = t.random_swap(text)\n",
        "    print('random_swap: ', new_text)\n",
        "\n",
        "    new_text = t.random_deletion(text, p=0.2)\n",
        "    print('random_deletion: ', new_text)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-bJlsYfomea",
        "outputId": "73876e22-b5d1-4f1a-dc1f-ec99815b8b38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:  Samantha took the bus.\n",
            "synonym replacement:  Samantha ask the bus.\n",
            "random_insertion:  Samantha took the take on bus.\n",
            "random_swap:  Samantha the took bus.\n",
            "random_deletion:  Samantha took the bus.\n",
            "\n",
            "original text:  There is no play with fire.\n",
            "synonym replacement:  There is no run with fire.\n",
            "random_insertion:  There there is no play with fire.\n",
            "random_swap:  There is fire. play with no\n",
            "random_deletion:  is no play with fire.\n",
            "\n",
            "original text:  Stop talking and open your book.\n",
            "synonym replacement:  catch talking and open your book.\n",
            "random_insertion:  Stop talking and hold on open your book.\n",
            "random_swap:  Stop book. and open your talking\n",
            "random_deletion:  Stop talking open your book.\n",
            "\n",
            "original text:  I want to be a computer engineer.\n",
            "synonym replacement:  I wish to be a computer engineer.\n",
            "random_insertion:  I want to be a computer  engineer.\n",
            "random_swap:  I a to be want computer engineer.\n",
            "random_deletion:  I want to be a computer engineer.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}